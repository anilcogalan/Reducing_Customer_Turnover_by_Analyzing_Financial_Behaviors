2023-04-09 20:23:07,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-09 20:23:07,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-09 20:23:07,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-09 20:23:07,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-09 20:23:08,472:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-09 20:23:36,198:INFO:PyCaret ClassificationExperiment
2023-04-09 20:23:36,199:INFO:Logging name: clf-default-name
2023-04-09 20:23:36,199:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-09 20:23:36,199:INFO:version 3.0.0
2023-04-09 20:23:36,199:INFO:Initializing setup()
2023-04-09 20:23:36,199:INFO:self.USI: bd24
2023-04-09 20:23:36,199:INFO:self._variable_keys: {'memory', 'USI', 'html_param', 'X', '_available_plots', 'exp_id', 'y_train', 'fold_generator', 'fix_imbalance', 'gpu_n_jobs_param', 'fold_shuffle_param', 'log_plots_param', 'pipeline', 'target_param', 'seed', 'n_jobs_param', 'is_multiclass', 'exp_name_log', 'idx', 'y_test', '_ml_usecase', 'gpu_param', 'X_train', 'X_test', 'data', 'fold_groups_param', 'y', 'logging_param'}
2023-04-09 20:23:36,199:INFO:Checking environment
2023-04-09 20:23:36,199:INFO:python_version: 3.9.15
2023-04-09 20:23:36,199:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-04-09 20:23:36,199:INFO:machine: AMD64
2023-04-09 20:23:36,209:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-09 20:23:36,209:INFO:Memory: svmem(total=34189594624, available=20377575424, percent=40.4, used=13812019200, free=20377575424)
2023-04-09 20:23:36,209:INFO:Physical Core: 6
2023-04-09 20:23:36,209:INFO:Logical Core: 12
2023-04-09 20:23:36,209:INFO:Checking libraries
2023-04-09 20:23:36,209:INFO:System:
2023-04-09 20:23:36,209:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-04-09 20:23:36,209:INFO:executable: C:\Users\anilc\anaconda3\python.exe
2023-04-09 20:23:36,209:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-09 20:23:36,209:INFO:PyCaret required dependencies:
2023-04-09 20:23:36,209:INFO:                 pip: 22.3.1
2023-04-09 20:23:36,209:INFO:          setuptools: 60.10.0
2023-04-09 20:23:36,209:INFO:             pycaret: 3.0.0
2023-04-09 20:23:36,209:INFO:             IPython: 8.7.0
2023-04-09 20:23:36,210:INFO:          ipywidgets: 7.6.5
2023-04-09 20:23:36,210:INFO:                tqdm: 4.64.1
2023-04-09 20:23:36,210:INFO:               numpy: 1.21.5
2023-04-09 20:23:36,210:INFO:              pandas: 1.4.4
2023-04-09 20:23:36,210:INFO:              jinja2: 3.1.2
2023-04-09 20:23:36,210:INFO:               scipy: 1.9.3
2023-04-09 20:23:36,210:INFO:              joblib: 1.2.0
2023-04-09 20:23:36,210:INFO:             sklearn: 1.0.2
2023-04-09 20:23:36,210:INFO:                pyod: 1.0.9
2023-04-09 20:23:36,210:INFO:            imblearn: 0.10.1
2023-04-09 20:23:36,210:INFO:   category_encoders: 2.6.0
2023-04-09 20:23:36,210:INFO:            lightgbm: 3.3.5
2023-04-09 20:23:36,210:INFO:               numba: 0.56.4
2023-04-09 20:23:36,210:INFO:            requests: 2.28.1
2023-04-09 20:23:36,210:INFO:          matplotlib: 3.6.2
2023-04-09 20:23:36,210:INFO:          scikitplot: 0.3.7
2023-04-09 20:23:36,210:INFO:         yellowbrick: 1.5
2023-04-09 20:23:36,210:INFO:              plotly: 5.9.0
2023-04-09 20:23:36,210:INFO:             kaleido: 0.2.1
2023-04-09 20:23:36,210:INFO:         statsmodels: 0.13.2
2023-04-09 20:23:36,210:INFO:              sktime: 0.16.1
2023-04-09 20:23:36,210:INFO:               tbats: 1.1.2
2023-04-09 20:23:36,210:INFO:            pmdarima: 2.0.3
2023-04-09 20:23:36,210:INFO:              psutil: 5.9.0
2023-04-09 20:23:36,210:INFO:PyCaret optional dependencies:
2023-04-09 20:23:36,224:INFO:                shap: Not installed
2023-04-09 20:23:36,224:INFO:           interpret: Not installed
2023-04-09 20:23:36,224:INFO:                umap: Not installed
2023-04-09 20:23:36,224:INFO:    pandas_profiling: 4.1.2
2023-04-09 20:23:36,224:INFO:  explainerdashboard: Not installed
2023-04-09 20:23:36,224:INFO:             autoviz: 0.1.58
2023-04-09 20:23:36,224:INFO:           fairlearn: Not installed
2023-04-09 20:23:36,224:INFO:             xgboost: 1.7.5
2023-04-09 20:23:36,224:INFO:            catboost: Not installed
2023-04-09 20:23:36,224:INFO:              kmodes: Not installed
2023-04-09 20:23:36,224:INFO:             mlxtend: 0.21.0
2023-04-09 20:23:36,224:INFO:       statsforecast: Not installed
2023-04-09 20:23:36,224:INFO:        tune_sklearn: Not installed
2023-04-09 20:23:36,224:INFO:                 ray: Not installed
2023-04-09 20:23:36,224:INFO:            hyperopt: Not installed
2023-04-09 20:23:36,224:INFO:              optuna: Not installed
2023-04-09 20:23:36,224:INFO:               skopt: Not installed
2023-04-09 20:23:36,224:INFO:              mlflow: Not installed
2023-04-09 20:23:36,224:INFO:              gradio: Not installed
2023-04-09 20:23:36,224:INFO:             fastapi: Not installed
2023-04-09 20:23:36,224:INFO:             uvicorn: Not installed
2023-04-09 20:23:36,224:INFO:              m2cgen: Not installed
2023-04-09 20:23:36,224:INFO:           evidently: Not installed
2023-04-09 20:23:36,224:INFO:               fugue: Not installed
2023-04-09 20:23:36,224:INFO:           streamlit: Not installed
2023-04-09 20:23:36,224:INFO:             prophet: Not installed
2023-04-09 20:23:36,225:INFO:None
2023-04-09 20:23:36,225:INFO:Set up data.
2023-04-09 20:23:36,235:INFO:Set up train/test split.
2023-04-09 20:23:36,244:INFO:Set up index.
2023-04-09 20:23:36,244:INFO:Set up folding strategy.
2023-04-09 20:23:36,244:INFO:Assigning column types.
2023-04-09 20:23:36,249:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-09 20:23:36,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-09 20:23:36,290:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:23:36,319:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:23:36,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:23:36,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-09 20:23:36,658:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:23:36,683:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:23:36,686:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:23:36,687:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-09 20:23:36,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:23:36,749:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:23:36,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:23:36,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:23:36,812:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:23:36,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:23:36,815:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-09 20:23:36,880:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:23:36,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:23:36,949:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:23:36,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:23:36,953:INFO:Preparing preprocessing pipeline...
2023-04-09 20:23:36,954:INFO:Set up simple imputation.
2023-04-09 20:23:36,957:INFO:Set up encoding of categorical features.
2023-04-09 20:23:37,014:INFO:Finished creating preprocessing pipeline.
2023-04-09 20:23:37,020:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'months_employed',
                                             'years_employed',
                                             'current_address_year',
                                             'personal_account_m',
                                             'personal_account_y', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['pay_schedule'],
                                    transformer=OneHotEncoder(cols=['pay_schedule'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-04-09 20:23:37,020:INFO:Creating final display dataframe.
2023-04-09 20:23:37,190:INFO:Setup _display_container:                     Description             Value
0                    Session id              7895
1                        Target          e_signed
2                   Target type            Binary
3           Original data shape       (17908, 21)
4        Transformed data shape       (17908, 24)
5   Transformed train set shape       (12535, 24)
6    Transformed test set shape        (5373, 24)
7              Numeric features                19
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              bd24
2023-04-09 20:23:37,253:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:23:37,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:23:37,317:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:23:37,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:23:37,320:INFO:setup() successfully completed in 1.16s...............
2023-04-09 20:23:37,320:INFO:Initializing compare_models()
2023-04-09 20:23:37,320:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-09 20:23:37,320:INFO:Checking exceptions
2023-04-09 20:23:37,325:INFO:Preparing display monitor
2023-04-09 20:23:37,327:INFO:Initializing Logistic Regression
2023-04-09 20:23:37,327:INFO:Total runtime is 0.0 minutes
2023-04-09 20:23:37,327:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:37,327:INFO:Initializing create_model()
2023-04-09 20:23:37,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:37,327:INFO:Checking exceptions
2023-04-09 20:23:37,328:INFO:Importing libraries
2023-04-09 20:23:37,328:INFO:Copying training dataset
2023-04-09 20:23:37,334:INFO:Defining folds
2023-04-09 20:23:37,334:INFO:Declaring metric variables
2023-04-09 20:23:37,334:INFO:Importing untrained model
2023-04-09 20:23:37,334:INFO:Logistic Regression Imported successfully
2023-04-09 20:23:37,335:INFO:Starting cross validation
2023-04-09 20:23:37,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:23:43,432:INFO:Calculating mean and std
2023-04-09 20:23:43,440:INFO:Creating metrics dataframe
2023-04-09 20:23:43,488:INFO:Uploading results into container
2023-04-09 20:23:43,488:INFO:Uploading model into container now
2023-04-09 20:23:43,489:INFO:_master_model_container: 1
2023-04-09 20:23:43,489:INFO:_display_container: 2
2023-04-09 20:23:43,489:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7895, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-09 20:23:43,489:INFO:create_model() successfully completed......................................
2023-04-09 20:23:43,559:INFO:SubProcess create_model() end ==================================
2023-04-09 20:23:43,559:INFO:Creating metrics dataframe
2023-04-09 20:23:43,562:INFO:Initializing K Neighbors Classifier
2023-04-09 20:23:43,562:INFO:Total runtime is 0.10390944083531697 minutes
2023-04-09 20:23:43,562:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:43,563:INFO:Initializing create_model()
2023-04-09 20:23:43,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:43,563:INFO:Checking exceptions
2023-04-09 20:23:43,563:INFO:Importing libraries
2023-04-09 20:23:43,563:INFO:Copying training dataset
2023-04-09 20:23:43,569:INFO:Defining folds
2023-04-09 20:23:43,569:INFO:Declaring metric variables
2023-04-09 20:23:43,569:INFO:Importing untrained model
2023-04-09 20:23:43,569:INFO:K Neighbors Classifier Imported successfully
2023-04-09 20:23:43,569:INFO:Starting cross validation
2023-04-09 20:23:43,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:23:44,818:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:44,848:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:44,850:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:44,896:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:44,902:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:44,930:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:45,026:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:45,196:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:47,195:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:47,205:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:23:47,632:INFO:Calculating mean and std
2023-04-09 20:23:47,632:INFO:Creating metrics dataframe
2023-04-09 20:23:47,690:INFO:Uploading results into container
2023-04-09 20:23:47,691:INFO:Uploading model into container now
2023-04-09 20:23:47,691:INFO:_master_model_container: 2
2023-04-09 20:23:47,691:INFO:_display_container: 2
2023-04-09 20:23:47,691:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-09 20:23:47,691:INFO:create_model() successfully completed......................................
2023-04-09 20:23:47,761:INFO:SubProcess create_model() end ==================================
2023-04-09 20:23:47,761:INFO:Creating metrics dataframe
2023-04-09 20:23:47,766:INFO:Initializing Naive Bayes
2023-04-09 20:23:47,766:INFO:Total runtime is 0.17398488521575928 minutes
2023-04-09 20:23:47,766:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:47,766:INFO:Initializing create_model()
2023-04-09 20:23:47,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:47,766:INFO:Checking exceptions
2023-04-09 20:23:47,766:INFO:Importing libraries
2023-04-09 20:23:47,766:INFO:Copying training dataset
2023-04-09 20:23:47,773:INFO:Defining folds
2023-04-09 20:23:47,773:INFO:Declaring metric variables
2023-04-09 20:23:47,773:INFO:Importing untrained model
2023-04-09 20:23:47,774:INFO:Naive Bayes Imported successfully
2023-04-09 20:23:47,774:INFO:Starting cross validation
2023-04-09 20:23:47,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:23:48,482:INFO:Calculating mean and std
2023-04-09 20:23:48,482:INFO:Creating metrics dataframe
2023-04-09 20:23:48,534:INFO:Uploading results into container
2023-04-09 20:23:48,535:INFO:Uploading model into container now
2023-04-09 20:23:48,535:INFO:_master_model_container: 3
2023-04-09 20:23:48,535:INFO:_display_container: 2
2023-04-09 20:23:48,536:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-09 20:23:48,536:INFO:create_model() successfully completed......................................
2023-04-09 20:23:48,605:INFO:SubProcess create_model() end ==================================
2023-04-09 20:23:48,605:INFO:Creating metrics dataframe
2023-04-09 20:23:48,609:INFO:Initializing Decision Tree Classifier
2023-04-09 20:23:48,609:INFO:Total runtime is 0.18803166548411052 minutes
2023-04-09 20:23:48,609:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:48,609:INFO:Initializing create_model()
2023-04-09 20:23:48,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:48,610:INFO:Checking exceptions
2023-04-09 20:23:48,610:INFO:Importing libraries
2023-04-09 20:23:48,610:INFO:Copying training dataset
2023-04-09 20:23:48,615:INFO:Defining folds
2023-04-09 20:23:48,615:INFO:Declaring metric variables
2023-04-09 20:23:48,616:INFO:Importing untrained model
2023-04-09 20:23:48,616:INFO:Decision Tree Classifier Imported successfully
2023-04-09 20:23:48,616:INFO:Starting cross validation
2023-04-09 20:23:48,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:23:49,740:INFO:Calculating mean and std
2023-04-09 20:23:49,742:INFO:Creating metrics dataframe
2023-04-09 20:23:49,796:INFO:Uploading results into container
2023-04-09 20:23:49,797:INFO:Uploading model into container now
2023-04-09 20:23:49,797:INFO:_master_model_container: 4
2023-04-09 20:23:49,797:INFO:_display_container: 2
2023-04-09 20:23:49,797:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7895, splitter='best')
2023-04-09 20:23:49,797:INFO:create_model() successfully completed......................................
2023-04-09 20:23:49,865:INFO:SubProcess create_model() end ==================================
2023-04-09 20:23:49,865:INFO:Creating metrics dataframe
2023-04-09 20:23:49,869:INFO:Initializing SVM - Linear Kernel
2023-04-09 20:23:49,869:INFO:Total runtime is 0.20903751452763875 minutes
2023-04-09 20:23:49,869:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:49,870:INFO:Initializing create_model()
2023-04-09 20:23:49,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:49,870:INFO:Checking exceptions
2023-04-09 20:23:49,870:INFO:Importing libraries
2023-04-09 20:23:49,870:INFO:Copying training dataset
2023-04-09 20:23:49,875:INFO:Defining folds
2023-04-09 20:23:49,875:INFO:Declaring metric variables
2023-04-09 20:23:49,875:INFO:Importing untrained model
2023-04-09 20:23:49,876:INFO:SVM - Linear Kernel Imported successfully
2023-04-09 20:23:49,876:INFO:Starting cross validation
2023-04-09 20:23:49,877:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:23:50,673:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,679:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,695:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,702:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,708:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,709:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:23:50,712:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,717:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,758:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,764:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:23:50,777:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,843:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:23:50,847:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:23:51,130:INFO:Calculating mean and std
2023-04-09 20:23:51,131:INFO:Creating metrics dataframe
2023-04-09 20:23:51,191:INFO:Uploading results into container
2023-04-09 20:23:51,192:INFO:Uploading model into container now
2023-04-09 20:23:51,192:INFO:_master_model_container: 5
2023-04-09 20:23:51,192:INFO:_display_container: 2
2023-04-09 20:23:51,192:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7895, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-09 20:23:51,192:INFO:create_model() successfully completed......................................
2023-04-09 20:23:51,264:INFO:SubProcess create_model() end ==================================
2023-04-09 20:23:51,264:INFO:Creating metrics dataframe
2023-04-09 20:23:51,268:INFO:Initializing Ridge Classifier
2023-04-09 20:23:51,268:INFO:Total runtime is 0.23234811623891194 minutes
2023-04-09 20:23:51,269:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:51,269:INFO:Initializing create_model()
2023-04-09 20:23:51,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:51,269:INFO:Checking exceptions
2023-04-09 20:23:51,269:INFO:Importing libraries
2023-04-09 20:23:51,269:INFO:Copying training dataset
2023-04-09 20:23:51,274:INFO:Defining folds
2023-04-09 20:23:51,275:INFO:Declaring metric variables
2023-04-09 20:23:51,275:INFO:Importing untrained model
2023-04-09 20:23:51,275:INFO:Ridge Classifier Imported successfully
2023-04-09 20:23:51,275:INFO:Starting cross validation
2023-04-09 20:23:51,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:23:51,459:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.359e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,459:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.35315e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,459:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.35824e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,461:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.3598e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,481:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.35361e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,489:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.35483e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,505:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.36145e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,517:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.35774e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,518:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.35921e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,518:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,520:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,525:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,533:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.35618e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:23:51,533:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,557:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,564:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,584:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,586:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,591:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,595:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:23:51,978:INFO:Calculating mean and std
2023-04-09 20:23:51,978:INFO:Creating metrics dataframe
2023-04-09 20:23:52,039:INFO:Uploading results into container
2023-04-09 20:23:52,039:INFO:Uploading model into container now
2023-04-09 20:23:52,040:INFO:_master_model_container: 6
2023-04-09 20:23:52,040:INFO:_display_container: 2
2023-04-09 20:23:52,040:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=7895, solver='auto', tol=0.001)
2023-04-09 20:23:52,040:INFO:create_model() successfully completed......................................
2023-04-09 20:23:52,108:INFO:SubProcess create_model() end ==================================
2023-04-09 20:23:52,108:INFO:Creating metrics dataframe
2023-04-09 20:23:52,113:INFO:Initializing Random Forest Classifier
2023-04-09 20:23:52,113:INFO:Total runtime is 0.24643235603968303 minutes
2023-04-09 20:23:52,113:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:52,113:INFO:Initializing create_model()
2023-04-09 20:23:52,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:52,113:INFO:Checking exceptions
2023-04-09 20:23:52,113:INFO:Importing libraries
2023-04-09 20:23:52,113:INFO:Copying training dataset
2023-04-09 20:23:52,119:INFO:Defining folds
2023-04-09 20:23:52,119:INFO:Declaring metric variables
2023-04-09 20:23:52,119:INFO:Importing untrained model
2023-04-09 20:23:52,119:INFO:Random Forest Classifier Imported successfully
2023-04-09 20:23:52,120:INFO:Starting cross validation
2023-04-09 20:23:52,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:23:55,480:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:23:55,713:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:23:55,996:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:23:57,193:INFO:Calculating mean and std
2023-04-09 20:23:57,194:INFO:Creating metrics dataframe
2023-04-09 20:23:57,259:INFO:Uploading results into container
2023-04-09 20:23:57,259:INFO:Uploading model into container now
2023-04-09 20:23:57,260:INFO:_master_model_container: 7
2023-04-09 20:23:57,260:INFO:_display_container: 2
2023-04-09 20:23:57,260:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7895, verbose=0, warm_start=False)
2023-04-09 20:23:57,260:INFO:create_model() successfully completed......................................
2023-04-09 20:23:57,330:INFO:SubProcess create_model() end ==================================
2023-04-09 20:23:57,330:INFO:Creating metrics dataframe
2023-04-09 20:23:57,335:INFO:Initializing Quadratic Discriminant Analysis
2023-04-09 20:23:57,336:INFO:Total runtime is 0.33348058064778646 minutes
2023-04-09 20:23:57,336:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:57,336:INFO:Initializing create_model()
2023-04-09 20:23:57,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:57,336:INFO:Checking exceptions
2023-04-09 20:23:57,336:INFO:Importing libraries
2023-04-09 20:23:57,336:INFO:Copying training dataset
2023-04-09 20:23:57,341:INFO:Defining folds
2023-04-09 20:23:57,342:INFO:Declaring metric variables
2023-04-09 20:23:57,342:INFO:Importing untrained model
2023-04-09 20:23:57,342:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-09 20:23:57,342:INFO:Starting cross validation
2023-04-09 20:23:57,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:23:57,541:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,541:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,542:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,542:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,548:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,558:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,562:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,580:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,602:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:57,607:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:23:58,164:INFO:Calculating mean and std
2023-04-09 20:23:58,164:INFO:Creating metrics dataframe
2023-04-09 20:23:58,229:INFO:Uploading results into container
2023-04-09 20:23:58,230:INFO:Uploading model into container now
2023-04-09 20:23:58,230:INFO:_master_model_container: 8
2023-04-09 20:23:58,230:INFO:_display_container: 2
2023-04-09 20:23:58,230:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-09 20:23:58,230:INFO:create_model() successfully completed......................................
2023-04-09 20:23:58,300:INFO:SubProcess create_model() end ==================================
2023-04-09 20:23:58,300:INFO:Creating metrics dataframe
2023-04-09 20:23:58,304:INFO:Initializing Ada Boost Classifier
2023-04-09 20:23:58,304:INFO:Total runtime is 0.34961050748825073 minutes
2023-04-09 20:23:58,304:INFO:SubProcess create_model() called ==================================
2023-04-09 20:23:58,305:INFO:Initializing create_model()
2023-04-09 20:23:58,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:23:58,305:INFO:Checking exceptions
2023-04-09 20:23:58,305:INFO:Importing libraries
2023-04-09 20:23:58,305:INFO:Copying training dataset
2023-04-09 20:23:58,310:INFO:Defining folds
2023-04-09 20:23:58,310:INFO:Declaring metric variables
2023-04-09 20:23:58,310:INFO:Importing untrained model
2023-04-09 20:23:58,310:INFO:Ada Boost Classifier Imported successfully
2023-04-09 20:23:58,311:INFO:Starting cross validation
2023-04-09 20:23:58,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:24:00,548:INFO:Calculating mean and std
2023-04-09 20:24:00,548:INFO:Creating metrics dataframe
2023-04-09 20:24:00,617:INFO:Uploading results into container
2023-04-09 20:24:00,618:INFO:Uploading model into container now
2023-04-09 20:24:00,618:INFO:_master_model_container: 9
2023-04-09 20:24:00,618:INFO:_display_container: 2
2023-04-09 20:24:00,618:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7895)
2023-04-09 20:24:00,619:INFO:create_model() successfully completed......................................
2023-04-09 20:24:00,688:INFO:SubProcess create_model() end ==================================
2023-04-09 20:24:00,689:INFO:Creating metrics dataframe
2023-04-09 20:24:00,692:INFO:Initializing Gradient Boosting Classifier
2023-04-09 20:24:00,692:INFO:Total runtime is 0.38941978613535566 minutes
2023-04-09 20:24:00,692:INFO:SubProcess create_model() called ==================================
2023-04-09 20:24:00,694:INFO:Initializing create_model()
2023-04-09 20:24:00,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:24:00,694:INFO:Checking exceptions
2023-04-09 20:24:00,694:INFO:Importing libraries
2023-04-09 20:24:00,694:INFO:Copying training dataset
2023-04-09 20:24:00,699:INFO:Defining folds
2023-04-09 20:24:00,699:INFO:Declaring metric variables
2023-04-09 20:24:00,699:INFO:Importing untrained model
2023-04-09 20:24:00,699:INFO:Gradient Boosting Classifier Imported successfully
2023-04-09 20:24:00,699:INFO:Starting cross validation
2023-04-09 20:24:00,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:24:06,386:INFO:Calculating mean and std
2023-04-09 20:24:06,386:INFO:Creating metrics dataframe
2023-04-09 20:24:06,458:INFO:Uploading results into container
2023-04-09 20:24:06,459:INFO:Uploading model into container now
2023-04-09 20:24:06,459:INFO:_master_model_container: 10
2023-04-09 20:24:06,459:INFO:_display_container: 2
2023-04-09 20:24:06,460:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7895, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-09 20:24:06,460:INFO:create_model() successfully completed......................................
2023-04-09 20:24:06,528:INFO:SubProcess create_model() end ==================================
2023-04-09 20:24:06,528:INFO:Creating metrics dataframe
2023-04-09 20:24:06,532:INFO:Initializing Linear Discriminant Analysis
2023-04-09 20:24:06,532:INFO:Total runtime is 0.4867452661196391 minutes
2023-04-09 20:24:06,532:INFO:SubProcess create_model() called ==================================
2023-04-09 20:24:06,532:INFO:Initializing create_model()
2023-04-09 20:24:06,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:24:06,532:INFO:Checking exceptions
2023-04-09 20:24:06,532:INFO:Importing libraries
2023-04-09 20:24:06,532:INFO:Copying training dataset
2023-04-09 20:24:06,537:INFO:Defining folds
2023-04-09 20:24:06,537:INFO:Declaring metric variables
2023-04-09 20:24:06,538:INFO:Importing untrained model
2023-04-09 20:24:06,538:INFO:Linear Discriminant Analysis Imported successfully
2023-04-09 20:24:06,538:INFO:Starting cross validation
2023-04-09 20:24:06,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:24:07,464:INFO:Calculating mean and std
2023-04-09 20:24:07,465:INFO:Creating metrics dataframe
2023-04-09 20:24:07,536:INFO:Uploading results into container
2023-04-09 20:24:07,537:INFO:Uploading model into container now
2023-04-09 20:24:07,537:INFO:_master_model_container: 11
2023-04-09 20:24:07,537:INFO:_display_container: 2
2023-04-09 20:24:07,537:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-09 20:24:07,537:INFO:create_model() successfully completed......................................
2023-04-09 20:24:07,605:INFO:SubProcess create_model() end ==================================
2023-04-09 20:24:07,605:INFO:Creating metrics dataframe
2023-04-09 20:24:07,610:INFO:Initializing Extra Trees Classifier
2023-04-09 20:24:07,610:INFO:Total runtime is 0.5047095497449239 minutes
2023-04-09 20:24:07,610:INFO:SubProcess create_model() called ==================================
2023-04-09 20:24:07,610:INFO:Initializing create_model()
2023-04-09 20:24:07,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:24:07,610:INFO:Checking exceptions
2023-04-09 20:24:07,610:INFO:Importing libraries
2023-04-09 20:24:07,610:INFO:Copying training dataset
2023-04-09 20:24:07,615:INFO:Defining folds
2023-04-09 20:24:07,615:INFO:Declaring metric variables
2023-04-09 20:24:07,616:INFO:Importing untrained model
2023-04-09 20:24:07,616:INFO:Extra Trees Classifier Imported successfully
2023-04-09 20:24:07,616:INFO:Starting cross validation
2023-04-09 20:24:07,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:24:10,138:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:24:10,179:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:24:11,418:INFO:Calculating mean and std
2023-04-09 20:24:11,419:INFO:Creating metrics dataframe
2023-04-09 20:24:11,533:INFO:Uploading results into container
2023-04-09 20:24:11,534:INFO:Uploading model into container now
2023-04-09 20:24:11,534:INFO:_master_model_container: 12
2023-04-09 20:24:11,534:INFO:_display_container: 2
2023-04-09 20:24:11,535:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7895, verbose=0, warm_start=False)
2023-04-09 20:24:11,535:INFO:create_model() successfully completed......................................
2023-04-09 20:24:11,603:INFO:SubProcess create_model() end ==================================
2023-04-09 20:24:11,603:INFO:Creating metrics dataframe
2023-04-09 20:24:11,607:INFO:Initializing Extreme Gradient Boosting
2023-04-09 20:24:11,607:INFO:Total runtime is 0.5713293512662252 minutes
2023-04-09 20:24:11,607:INFO:SubProcess create_model() called ==================================
2023-04-09 20:24:11,608:INFO:Initializing create_model()
2023-04-09 20:24:11,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:24:11,608:INFO:Checking exceptions
2023-04-09 20:24:11,608:INFO:Importing libraries
2023-04-09 20:24:11,608:INFO:Copying training dataset
2023-04-09 20:24:11,613:INFO:Defining folds
2023-04-09 20:24:11,613:INFO:Declaring metric variables
2023-04-09 20:24:11,614:INFO:Importing untrained model
2023-04-09 20:24:11,614:INFO:Extreme Gradient Boosting Imported successfully
2023-04-09 20:24:11,614:INFO:Starting cross validation
2023-04-09 20:24:11,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:24:16,024:INFO:Calculating mean and std
2023-04-09 20:24:16,025:INFO:Creating metrics dataframe
2023-04-09 20:24:16,114:INFO:Uploading results into container
2023-04-09 20:24:16,115:INFO:Uploading model into container now
2023-04-09 20:24:16,115:INFO:_master_model_container: 13
2023-04-09 20:24:16,115:INFO:_display_container: 2
2023-04-09 20:24:16,116:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-09 20:24:16,116:INFO:create_model() successfully completed......................................
2023-04-09 20:24:16,186:INFO:SubProcess create_model() end ==================================
2023-04-09 20:24:16,186:INFO:Creating metrics dataframe
2023-04-09 20:24:16,191:INFO:Initializing Light Gradient Boosting Machine
2023-04-09 20:24:16,191:INFO:Total runtime is 0.6477280855178833 minutes
2023-04-09 20:24:16,191:INFO:SubProcess create_model() called ==================================
2023-04-09 20:24:16,191:INFO:Initializing create_model()
2023-04-09 20:24:16,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:24:16,191:INFO:Checking exceptions
2023-04-09 20:24:16,191:INFO:Importing libraries
2023-04-09 20:24:16,191:INFO:Copying training dataset
2023-04-09 20:24:16,196:INFO:Defining folds
2023-04-09 20:24:16,196:INFO:Declaring metric variables
2023-04-09 20:24:16,196:INFO:Importing untrained model
2023-04-09 20:24:16,196:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:24:16,196:INFO:Starting cross validation
2023-04-09 20:24:16,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:24:19,970:INFO:Calculating mean and std
2023-04-09 20:24:19,971:INFO:Creating metrics dataframe
2023-04-09 20:24:20,072:INFO:Uploading results into container
2023-04-09 20:24:20,072:INFO:Uploading model into container now
2023-04-09 20:24:20,073:INFO:_master_model_container: 14
2023-04-09 20:24:20,073:INFO:_display_container: 2
2023-04-09 20:24:20,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7895, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:24:20,074:INFO:create_model() successfully completed......................................
2023-04-09 20:24:20,147:INFO:SubProcess create_model() end ==================================
2023-04-09 20:24:20,147:INFO:Creating metrics dataframe
2023-04-09 20:24:20,152:INFO:Initializing Dummy Classifier
2023-04-09 20:24:20,152:INFO:Total runtime is 0.7137457847595214 minutes
2023-04-09 20:24:20,152:INFO:SubProcess create_model() called ==================================
2023-04-09 20:24:20,152:INFO:Initializing create_model()
2023-04-09 20:24:20,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A11AAE9D0>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:24:20,153:INFO:Checking exceptions
2023-04-09 20:24:20,153:INFO:Importing libraries
2023-04-09 20:24:20,153:INFO:Copying training dataset
2023-04-09 20:24:20,158:INFO:Defining folds
2023-04-09 20:24:20,158:INFO:Declaring metric variables
2023-04-09 20:24:20,158:INFO:Importing untrained model
2023-04-09 20:24:20,158:INFO:Dummy Classifier Imported successfully
2023-04-09 20:24:20,158:INFO:Starting cross validation
2023-04-09 20:24:20,159:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:24:21,410:INFO:Calculating mean and std
2023-04-09 20:24:21,411:INFO:Creating metrics dataframe
2023-04-09 20:24:21,517:INFO:Uploading results into container
2023-04-09 20:24:21,518:INFO:Uploading model into container now
2023-04-09 20:24:21,518:INFO:_master_model_container: 15
2023-04-09 20:24:21,519:INFO:_display_container: 2
2023-04-09 20:24:21,519:INFO:DummyClassifier(constant=None, random_state=7895, strategy='prior')
2023-04-09 20:24:21,519:INFO:create_model() successfully completed......................................
2023-04-09 20:24:21,597:INFO:SubProcess create_model() end ==================================
2023-04-09 20:24:21,597:INFO:Creating metrics dataframe
2023-04-09 20:24:21,603:INFO:Initializing create_model()
2023-04-09 20:24:21,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7895, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:24:21,603:INFO:Checking exceptions
2023-04-09 20:24:21,603:INFO:Importing libraries
2023-04-09 20:24:21,603:INFO:Copying training dataset
2023-04-09 20:24:21,609:INFO:Defining folds
2023-04-09 20:24:21,609:INFO:Declaring metric variables
2023-04-09 20:24:21,609:INFO:Importing untrained model
2023-04-09 20:24:21,610:INFO:Declaring custom model
2023-04-09 20:24:21,610:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:24:21,611:INFO:Cross validation set to False
2023-04-09 20:24:21,611:INFO:Fitting Model
2023-04-09 20:24:21,973:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7895, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:24:21,973:INFO:create_model() successfully completed......................................
2023-04-09 20:24:22,058:INFO:_master_model_container: 15
2023-04-09 20:24:22,058:INFO:_display_container: 2
2023-04-09 20:24:22,058:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7895, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:24:22,059:INFO:compare_models() successfully completed......................................
2023-04-09 20:24:22,059:INFO:Initializing finalize_model()
2023-04-09 20:24:22,059:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7895, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-09 20:24:22,059:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7895, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:24:22,063:INFO:Initializing create_model()
2023-04-09 20:24:22,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7895, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-09 20:24:22,063:INFO:Checking exceptions
2023-04-09 20:24:22,064:INFO:Importing libraries
2023-04-09 20:24:22,064:INFO:Copying training dataset
2023-04-09 20:24:22,064:INFO:Defining folds
2023-04-09 20:24:22,064:INFO:Declaring metric variables
2023-04-09 20:24:22,065:INFO:Importing untrained model
2023-04-09 20:24:22,065:INFO:Declaring custom model
2023-04-09 20:24:22,065:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:24:22,066:INFO:Cross validation set to False
2023-04-09 20:24:22,066:INFO:Fitting Model
2023-04-09 20:24:22,535:INFO:Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'months_employed',
                                             'years_employed',
                                             'current_address_year',
                                             'personal_account_m',
                                             'personal_account_y', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=7895, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-04-09 20:24:22,535:INFO:create_model() successfully completed......................................
2023-04-09 20:24:22,654:INFO:_master_model_container: 15
2023-04-09 20:24:22,654:INFO:_display_container: 2
2023-04-09 20:24:22,662:INFO:Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'months_employed',
                                             'years_employed',
                                             'current_address_year',
                                             'personal_account_m',
                                             'personal_account_y', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=7895, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-04-09 20:24:22,662:INFO:finalize_model() successfully completed......................................
2023-04-09 20:24:22,798:INFO:Initializing predict_model()
2023-04-09 20:24:22,798:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1DC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'months_employed',
                                             'years_employed',
                                             'current_address_year',
                                             'personal_account_m',
                                             'personal_account_y', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=7895, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000022A0A7F6DC0>)
2023-04-09 20:24:22,798:INFO:Checking exceptions
2023-04-09 20:24:22,798:INFO:Preloading libraries
2023-04-09 20:24:22,798:INFO:Set up data.
2023-04-09 20:24:22,811:INFO:Set up index.
2023-04-09 20:26:37,038:INFO:PyCaret ClassificationExperiment
2023-04-09 20:26:37,039:INFO:Logging name: clf-default-name
2023-04-09 20:26:37,039:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-09 20:26:37,039:INFO:version 3.0.0
2023-04-09 20:26:37,039:INFO:Initializing setup()
2023-04-09 20:26:37,039:INFO:self.USI: 8e69
2023-04-09 20:26:37,039:INFO:self._variable_keys: {'memory', 'USI', 'html_param', 'X', '_available_plots', 'exp_id', 'y_train', 'fold_generator', 'fix_imbalance', 'gpu_n_jobs_param', 'fold_shuffle_param', 'log_plots_param', 'pipeline', 'target_param', 'seed', 'n_jobs_param', 'is_multiclass', 'exp_name_log', 'idx', 'y_test', '_ml_usecase', 'gpu_param', 'X_train', 'X_test', 'data', 'fold_groups_param', 'y', 'logging_param'}
2023-04-09 20:26:37,039:INFO:Checking environment
2023-04-09 20:26:37,039:INFO:python_version: 3.9.15
2023-04-09 20:26:37,039:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-04-09 20:26:37,039:INFO:machine: AMD64
2023-04-09 20:26:37,039:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-09 20:26:37,039:INFO:Memory: svmem(total=34189594624, available=18840813568, percent=44.9, used=15348781056, free=18840813568)
2023-04-09 20:26:37,039:INFO:Physical Core: 6
2023-04-09 20:26:37,039:INFO:Logical Core: 12
2023-04-09 20:26:37,039:INFO:Checking libraries
2023-04-09 20:26:37,039:INFO:System:
2023-04-09 20:26:37,039:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-04-09 20:26:37,039:INFO:executable: C:\Users\anilc\anaconda3\python.exe
2023-04-09 20:26:37,039:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-09 20:26:37,039:INFO:PyCaret required dependencies:
2023-04-09 20:26:37,039:INFO:                 pip: 22.3.1
2023-04-09 20:26:37,039:INFO:          setuptools: 60.10.0
2023-04-09 20:26:37,039:INFO:             pycaret: 3.0.0
2023-04-09 20:26:37,039:INFO:             IPython: 8.7.0
2023-04-09 20:26:37,040:INFO:          ipywidgets: 7.6.5
2023-04-09 20:26:37,040:INFO:                tqdm: 4.64.1
2023-04-09 20:26:37,040:INFO:               numpy: 1.21.5
2023-04-09 20:26:37,040:INFO:              pandas: 1.4.4
2023-04-09 20:26:37,040:INFO:              jinja2: 3.1.2
2023-04-09 20:26:37,040:INFO:               scipy: 1.9.3
2023-04-09 20:26:37,040:INFO:              joblib: 1.2.0
2023-04-09 20:26:37,040:INFO:             sklearn: 1.0.2
2023-04-09 20:26:37,040:INFO:                pyod: 1.0.9
2023-04-09 20:26:37,040:INFO:            imblearn: 0.10.1
2023-04-09 20:26:37,040:INFO:   category_encoders: 2.6.0
2023-04-09 20:26:37,040:INFO:            lightgbm: 3.3.5
2023-04-09 20:26:37,040:INFO:               numba: 0.56.4
2023-04-09 20:26:37,040:INFO:            requests: 2.28.1
2023-04-09 20:26:37,040:INFO:          matplotlib: 3.6.2
2023-04-09 20:26:37,040:INFO:          scikitplot: 0.3.7
2023-04-09 20:26:37,040:INFO:         yellowbrick: 1.5
2023-04-09 20:26:37,040:INFO:              plotly: 5.9.0
2023-04-09 20:26:37,040:INFO:             kaleido: 0.2.1
2023-04-09 20:26:37,040:INFO:         statsmodels: 0.13.2
2023-04-09 20:26:37,040:INFO:              sktime: 0.16.1
2023-04-09 20:26:37,040:INFO:               tbats: 1.1.2
2023-04-09 20:26:37,040:INFO:            pmdarima: 2.0.3
2023-04-09 20:26:37,040:INFO:              psutil: 5.9.0
2023-04-09 20:26:37,040:INFO:PyCaret optional dependencies:
2023-04-09 20:26:37,040:INFO:                shap: Not installed
2023-04-09 20:26:37,040:INFO:           interpret: Not installed
2023-04-09 20:26:37,040:INFO:                umap: Not installed
2023-04-09 20:26:37,040:INFO:    pandas_profiling: 4.1.2
2023-04-09 20:26:37,041:INFO:  explainerdashboard: Not installed
2023-04-09 20:26:37,041:INFO:             autoviz: 0.1.58
2023-04-09 20:26:37,041:INFO:           fairlearn: Not installed
2023-04-09 20:26:37,041:INFO:             xgboost: 1.7.5
2023-04-09 20:26:37,041:INFO:            catboost: Not installed
2023-04-09 20:26:37,041:INFO:              kmodes: Not installed
2023-04-09 20:26:37,041:INFO:             mlxtend: 0.21.0
2023-04-09 20:26:37,041:INFO:       statsforecast: Not installed
2023-04-09 20:26:37,041:INFO:        tune_sklearn: Not installed
2023-04-09 20:26:37,041:INFO:                 ray: Not installed
2023-04-09 20:26:37,041:INFO:            hyperopt: Not installed
2023-04-09 20:26:37,041:INFO:              optuna: Not installed
2023-04-09 20:26:37,041:INFO:               skopt: Not installed
2023-04-09 20:26:37,041:INFO:              mlflow: Not installed
2023-04-09 20:26:37,041:INFO:              gradio: Not installed
2023-04-09 20:26:37,041:INFO:             fastapi: Not installed
2023-04-09 20:26:37,041:INFO:             uvicorn: Not installed
2023-04-09 20:26:37,041:INFO:              m2cgen: Not installed
2023-04-09 20:26:37,041:INFO:           evidently: Not installed
2023-04-09 20:26:37,041:INFO:               fugue: Not installed
2023-04-09 20:26:37,041:INFO:           streamlit: Not installed
2023-04-09 20:26:37,041:INFO:             prophet: Not installed
2023-04-09 20:26:37,041:INFO:None
2023-04-09 20:26:37,041:INFO:Set up data.
2023-04-09 20:26:37,050:INFO:Set up train/test split.
2023-04-09 20:26:37,059:INFO:Set up index.
2023-04-09 20:26:37,059:INFO:Set up folding strategy.
2023-04-09 20:26:37,059:INFO:Assigning column types.
2023-04-09 20:26:37,063:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-09 20:26:37,102:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-09 20:26:37,102:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:26:37,126:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:26:37,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:26:37,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-09 20:26:37,167:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:26:37,191:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:26:37,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:26:37,194:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-09 20:26:37,231:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:26:37,255:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:26:37,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:26:37,299:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:26:37,322:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:26:37,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:26:37,324:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-09 20:26:37,387:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:26:37,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:26:37,449:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:26:37,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:26:37,453:INFO:Preparing preprocessing pipeline...
2023-04-09 20:26:37,454:INFO:Set up simple imputation.
2023-04-09 20:26:37,457:INFO:Set up encoding of categorical features.
2023-04-09 20:26:37,513:INFO:Finished creating preprocessing pipeline.
2023-04-09 20:26:37,518:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'months_employed',
                                             'years_employed',
                                             'current_address_year',
                                             'personal_account_m',
                                             'personal_account_y', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['pay_schedule'],
                                    transformer=OneHotEncoder(cols=['pay_schedule'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-04-09 20:26:37,518:INFO:Creating final display dataframe.
2023-04-09 20:26:37,687:INFO:Setup _display_container:                     Description             Value
0                    Session id              4017
1                        Target          e_signed
2                   Target type            Binary
3           Original data shape       (17908, 21)
4        Transformed data shape       (17908, 24)
5   Transformed train set shape       (12535, 24)
6    Transformed test set shape        (5373, 24)
7              Numeric features                19
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              8e69
2023-04-09 20:26:37,760:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:26:37,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:26:37,833:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:26:37,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:26:37,836:INFO:setup() successfully completed in 0.87s...............
2023-04-09 20:26:37,901:INFO:Initializing compare_models()
2023-04-09 20:26:37,901:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-09 20:26:37,902:INFO:Checking exceptions
2023-04-09 20:26:37,906:INFO:Preparing display monitor
2023-04-09 20:26:37,908:INFO:Initializing Logistic Regression
2023-04-09 20:26:37,908:INFO:Total runtime is 0.0 minutes
2023-04-09 20:26:37,908:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:37,908:INFO:Initializing create_model()
2023-04-09 20:26:37,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:37,908:INFO:Checking exceptions
2023-04-09 20:26:37,908:INFO:Importing libraries
2023-04-09 20:26:37,908:INFO:Copying training dataset
2023-04-09 20:26:37,913:INFO:Defining folds
2023-04-09 20:26:37,913:INFO:Declaring metric variables
2023-04-09 20:26:37,913:INFO:Importing untrained model
2023-04-09 20:26:37,914:INFO:Logistic Regression Imported successfully
2023-04-09 20:26:37,914:INFO:Starting cross validation
2023-04-09 20:26:37,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:39,070:INFO:Calculating mean and std
2023-04-09 20:26:39,071:INFO:Creating metrics dataframe
2023-04-09 20:26:39,160:INFO:Uploading results into container
2023-04-09 20:26:39,160:INFO:Uploading model into container now
2023-04-09 20:26:39,161:INFO:_master_model_container: 1
2023-04-09 20:26:39,161:INFO:_display_container: 2
2023-04-09 20:26:39,161:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4017, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-09 20:26:39,161:INFO:create_model() successfully completed......................................
2023-04-09 20:26:39,233:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:39,233:INFO:Creating metrics dataframe
2023-04-09 20:26:39,236:INFO:Initializing K Neighbors Classifier
2023-04-09 20:26:39,236:INFO:Total runtime is 0.022143105665842693 minutes
2023-04-09 20:26:39,236:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:39,236:INFO:Initializing create_model()
2023-04-09 20:26:39,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:39,236:INFO:Checking exceptions
2023-04-09 20:26:39,236:INFO:Importing libraries
2023-04-09 20:26:39,236:INFO:Copying training dataset
2023-04-09 20:26:39,242:INFO:Defining folds
2023-04-09 20:26:39,242:INFO:Declaring metric variables
2023-04-09 20:26:39,242:INFO:Importing untrained model
2023-04-09 20:26:39,242:INFO:K Neighbors Classifier Imported successfully
2023-04-09 20:26:39,242:INFO:Starting cross validation
2023-04-09 20:26:39,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:40,634:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:40,650:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:40,678:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:40,738:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:40,789:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:40,794:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:40,883:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:40,978:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:40,981:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:41,015:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:26:43,339:INFO:Calculating mean and std
2023-04-09 20:26:43,340:INFO:Creating metrics dataframe
2023-04-09 20:26:43,439:INFO:Uploading results into container
2023-04-09 20:26:43,439:INFO:Uploading model into container now
2023-04-09 20:26:43,439:INFO:_master_model_container: 2
2023-04-09 20:26:43,439:INFO:_display_container: 2
2023-04-09 20:26:43,440:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-09 20:26:43,440:INFO:create_model() successfully completed......................................
2023-04-09 20:26:43,510:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:43,510:INFO:Creating metrics dataframe
2023-04-09 20:26:43,514:INFO:Initializing Naive Bayes
2023-04-09 20:26:43,514:INFO:Total runtime is 0.09343790610631307 minutes
2023-04-09 20:26:43,514:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:43,514:INFO:Initializing create_model()
2023-04-09 20:26:43,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:43,515:INFO:Checking exceptions
2023-04-09 20:26:43,515:INFO:Importing libraries
2023-04-09 20:26:43,515:INFO:Copying training dataset
2023-04-09 20:26:43,520:INFO:Defining folds
2023-04-09 20:26:43,520:INFO:Declaring metric variables
2023-04-09 20:26:43,520:INFO:Importing untrained model
2023-04-09 20:26:43,520:INFO:Naive Bayes Imported successfully
2023-04-09 20:26:43,520:INFO:Starting cross validation
2023-04-09 20:26:43,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:44,615:INFO:Calculating mean and std
2023-04-09 20:26:44,615:INFO:Creating metrics dataframe
2023-04-09 20:26:44,704:INFO:Uploading results into container
2023-04-09 20:26:44,706:INFO:Uploading model into container now
2023-04-09 20:26:44,706:INFO:_master_model_container: 3
2023-04-09 20:26:44,706:INFO:_display_container: 2
2023-04-09 20:26:44,706:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-09 20:26:44,706:INFO:create_model() successfully completed......................................
2023-04-09 20:26:44,776:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:44,776:INFO:Creating metrics dataframe
2023-04-09 20:26:44,780:INFO:Initializing Decision Tree Classifier
2023-04-09 20:26:44,780:INFO:Total runtime is 0.11454385916392008 minutes
2023-04-09 20:26:44,780:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:44,781:INFO:Initializing create_model()
2023-04-09 20:26:44,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:44,781:INFO:Checking exceptions
2023-04-09 20:26:44,781:INFO:Importing libraries
2023-04-09 20:26:44,781:INFO:Copying training dataset
2023-04-09 20:26:44,787:INFO:Defining folds
2023-04-09 20:26:44,788:INFO:Declaring metric variables
2023-04-09 20:26:44,788:INFO:Importing untrained model
2023-04-09 20:26:44,788:INFO:Decision Tree Classifier Imported successfully
2023-04-09 20:26:44,788:INFO:Starting cross validation
2023-04-09 20:26:44,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:46,176:INFO:Calculating mean and std
2023-04-09 20:26:46,176:INFO:Creating metrics dataframe
2023-04-09 20:26:46,270:INFO:Uploading results into container
2023-04-09 20:26:46,270:INFO:Uploading model into container now
2023-04-09 20:26:46,271:INFO:_master_model_container: 4
2023-04-09 20:26:46,271:INFO:_display_container: 2
2023-04-09 20:26:46,271:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4017, splitter='best')
2023-04-09 20:26:46,271:INFO:create_model() successfully completed......................................
2023-04-09 20:26:46,341:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:46,341:INFO:Creating metrics dataframe
2023-04-09 20:26:46,345:INFO:Initializing SVM - Linear Kernel
2023-04-09 20:26:46,346:INFO:Total runtime is 0.14063021739323933 minutes
2023-04-09 20:26:46,346:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:46,346:INFO:Initializing create_model()
2023-04-09 20:26:46,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:46,346:INFO:Checking exceptions
2023-04-09 20:26:46,346:INFO:Importing libraries
2023-04-09 20:26:46,346:INFO:Copying training dataset
2023-04-09 20:26:46,353:INFO:Defining folds
2023-04-09 20:26:46,353:INFO:Declaring metric variables
2023-04-09 20:26:46,353:INFO:Importing untrained model
2023-04-09 20:26:46,354:INFO:SVM - Linear Kernel Imported successfully
2023-04-09 20:26:46,354:INFO:Starting cross validation
2023-04-09 20:26:46,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:47,146:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,151:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,161:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,165:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,168:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:26:47,176:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,225:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,230:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,331:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,352:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,352:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:26:47,363:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:26:47,985:INFO:Calculating mean and std
2023-04-09 20:26:47,986:INFO:Creating metrics dataframe
2023-04-09 20:26:48,106:INFO:Uploading results into container
2023-04-09 20:26:48,107:INFO:Uploading model into container now
2023-04-09 20:26:48,107:INFO:_master_model_container: 5
2023-04-09 20:26:48,107:INFO:_display_container: 2
2023-04-09 20:26:48,107:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4017, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-09 20:26:48,107:INFO:create_model() successfully completed......................................
2023-04-09 20:26:48,179:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:48,179:INFO:Creating metrics dataframe
2023-04-09 20:26:48,185:INFO:Initializing Ridge Classifier
2023-04-09 20:26:48,185:INFO:Total runtime is 0.17128314574559528 minutes
2023-04-09 20:26:48,185:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:48,185:INFO:Initializing create_model()
2023-04-09 20:26:48,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:48,185:INFO:Checking exceptions
2023-04-09 20:26:48,185:INFO:Importing libraries
2023-04-09 20:26:48,185:INFO:Copying training dataset
2023-04-09 20:26:48,192:INFO:Defining folds
2023-04-09 20:26:48,192:INFO:Declaring metric variables
2023-04-09 20:26:48,192:INFO:Importing untrained model
2023-04-09 20:26:48,192:INFO:Ridge Classifier Imported successfully
2023-04-09 20:26:48,193:INFO:Starting cross validation
2023-04-09 20:26:48,193:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:48,377:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.34698e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,385:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.347e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,405:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.34668e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,405:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.35417e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,412:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.34768e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,421:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.34305e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,421:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.33874e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,442:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.34542e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,449:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.34758e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,449:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,459:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.34421e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-04-09 20:26:48,462:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,462:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,475:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,488:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,497:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,499:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,520:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,525:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:48,537:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:26:49,305:INFO:Calculating mean and std
2023-04-09 20:26:49,306:INFO:Creating metrics dataframe
2023-04-09 20:26:49,413:INFO:Uploading results into container
2023-04-09 20:26:49,414:INFO:Uploading model into container now
2023-04-09 20:26:49,414:INFO:_master_model_container: 6
2023-04-09 20:26:49,414:INFO:_display_container: 2
2023-04-09 20:26:49,415:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=4017, solver='auto', tol=0.001)
2023-04-09 20:26:49,415:INFO:create_model() successfully completed......................................
2023-04-09 20:26:49,484:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:49,484:INFO:Creating metrics dataframe
2023-04-09 20:26:49,488:INFO:Initializing Random Forest Classifier
2023-04-09 20:26:49,488:INFO:Total runtime is 0.1929970820744832 minutes
2023-04-09 20:26:49,488:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:49,489:INFO:Initializing create_model()
2023-04-09 20:26:49,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:49,489:INFO:Checking exceptions
2023-04-09 20:26:49,489:INFO:Importing libraries
2023-04-09 20:26:49,489:INFO:Copying training dataset
2023-04-09 20:26:49,493:INFO:Defining folds
2023-04-09 20:26:49,493:INFO:Declaring metric variables
2023-04-09 20:26:49,493:INFO:Importing untrained model
2023-04-09 20:26:49,494:INFO:Random Forest Classifier Imported successfully
2023-04-09 20:26:49,494:INFO:Starting cross validation
2023-04-09 20:26:49,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:53,163:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:26:53,288:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:26:55,085:INFO:Calculating mean and std
2023-04-09 20:26:55,086:INFO:Creating metrics dataframe
2023-04-09 20:26:55,195:INFO:Uploading results into container
2023-04-09 20:26:55,196:INFO:Uploading model into container now
2023-04-09 20:26:55,196:INFO:_master_model_container: 7
2023-04-09 20:26:55,196:INFO:_display_container: 2
2023-04-09 20:26:55,196:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4017, verbose=0, warm_start=False)
2023-04-09 20:26:55,196:INFO:create_model() successfully completed......................................
2023-04-09 20:26:55,270:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:55,270:INFO:Creating metrics dataframe
2023-04-09 20:26:55,274:INFO:Initializing Quadratic Discriminant Analysis
2023-04-09 20:26:55,274:INFO:Total runtime is 0.2894427378972371 minutes
2023-04-09 20:26:55,274:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:55,274:INFO:Initializing create_model()
2023-04-09 20:26:55,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:55,275:INFO:Checking exceptions
2023-04-09 20:26:55,275:INFO:Importing libraries
2023-04-09 20:26:55,275:INFO:Copying training dataset
2023-04-09 20:26:55,281:INFO:Defining folds
2023-04-09 20:26:55,281:INFO:Declaring metric variables
2023-04-09 20:26:55,281:INFO:Importing untrained model
2023-04-09 20:26:55,281:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-09 20:26:55,282:INFO:Starting cross validation
2023-04-09 20:26:55,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:55,448:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,449:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,474:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,481:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,486:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,488:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,496:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,521:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,522:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:55,546:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-09 20:26:56,412:INFO:Calculating mean and std
2023-04-09 20:26:56,413:INFO:Creating metrics dataframe
2023-04-09 20:26:56,519:INFO:Uploading results into container
2023-04-09 20:26:56,519:INFO:Uploading model into container now
2023-04-09 20:26:56,520:INFO:_master_model_container: 8
2023-04-09 20:26:56,520:INFO:_display_container: 2
2023-04-09 20:26:56,520:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-09 20:26:56,520:INFO:create_model() successfully completed......................................
2023-04-09 20:26:56,589:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:56,589:INFO:Creating metrics dataframe
2023-04-09 20:26:56,593:INFO:Initializing Ada Boost Classifier
2023-04-09 20:26:56,593:INFO:Total runtime is 0.3114244023958842 minutes
2023-04-09 20:26:56,594:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:56,594:INFO:Initializing create_model()
2023-04-09 20:26:56,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:56,594:INFO:Checking exceptions
2023-04-09 20:26:56,594:INFO:Importing libraries
2023-04-09 20:26:56,594:INFO:Copying training dataset
2023-04-09 20:26:56,600:INFO:Defining folds
2023-04-09 20:26:56,600:INFO:Declaring metric variables
2023-04-09 20:26:56,600:INFO:Importing untrained model
2023-04-09 20:26:56,600:INFO:Ada Boost Classifier Imported successfully
2023-04-09 20:26:56,601:INFO:Starting cross validation
2023-04-09 20:26:56,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:26:59,266:INFO:Calculating mean and std
2023-04-09 20:26:59,267:INFO:Creating metrics dataframe
2023-04-09 20:26:59,377:INFO:Uploading results into container
2023-04-09 20:26:59,378:INFO:Uploading model into container now
2023-04-09 20:26:59,378:INFO:_master_model_container: 9
2023-04-09 20:26:59,378:INFO:_display_container: 2
2023-04-09 20:26:59,379:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4017)
2023-04-09 20:26:59,379:INFO:create_model() successfully completed......................................
2023-04-09 20:26:59,448:INFO:SubProcess create_model() end ==================================
2023-04-09 20:26:59,449:INFO:Creating metrics dataframe
2023-04-09 20:26:59,453:INFO:Initializing Gradient Boosting Classifier
2023-04-09 20:26:59,453:INFO:Total runtime is 0.359088937441508 minutes
2023-04-09 20:26:59,453:INFO:SubProcess create_model() called ==================================
2023-04-09 20:26:59,453:INFO:Initializing create_model()
2023-04-09 20:26:59,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:26:59,453:INFO:Checking exceptions
2023-04-09 20:26:59,453:INFO:Importing libraries
2023-04-09 20:26:59,453:INFO:Copying training dataset
2023-04-09 20:26:59,459:INFO:Defining folds
2023-04-09 20:26:59,459:INFO:Declaring metric variables
2023-04-09 20:26:59,459:INFO:Importing untrained model
2023-04-09 20:26:59,460:INFO:Gradient Boosting Classifier Imported successfully
2023-04-09 20:26:59,460:INFO:Starting cross validation
2023-04-09 20:26:59,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:27:05,773:INFO:Calculating mean and std
2023-04-09 20:27:05,774:INFO:Creating metrics dataframe
2023-04-09 20:27:05,892:INFO:Uploading results into container
2023-04-09 20:27:05,893:INFO:Uploading model into container now
2023-04-09 20:27:05,893:INFO:_master_model_container: 10
2023-04-09 20:27:05,893:INFO:_display_container: 2
2023-04-09 20:27:05,893:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4017, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-09 20:27:05,893:INFO:create_model() successfully completed......................................
2023-04-09 20:27:05,964:INFO:SubProcess create_model() end ==================================
2023-04-09 20:27:05,964:INFO:Creating metrics dataframe
2023-04-09 20:27:05,968:INFO:Initializing Linear Discriminant Analysis
2023-04-09 20:27:05,968:INFO:Total runtime is 0.4676726261774699 minutes
2023-04-09 20:27:05,968:INFO:SubProcess create_model() called ==================================
2023-04-09 20:27:05,968:INFO:Initializing create_model()
2023-04-09 20:27:05,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:27:05,968:INFO:Checking exceptions
2023-04-09 20:27:05,969:INFO:Importing libraries
2023-04-09 20:27:05,969:INFO:Copying training dataset
2023-04-09 20:27:05,975:INFO:Defining folds
2023-04-09 20:27:05,975:INFO:Declaring metric variables
2023-04-09 20:27:05,976:INFO:Importing untrained model
2023-04-09 20:27:05,976:INFO:Linear Discriminant Analysis Imported successfully
2023-04-09 20:27:05,976:INFO:Starting cross validation
2023-04-09 20:27:05,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:27:07,226:INFO:Calculating mean and std
2023-04-09 20:27:07,226:INFO:Creating metrics dataframe
2023-04-09 20:27:07,349:INFO:Uploading results into container
2023-04-09 20:27:07,350:INFO:Uploading model into container now
2023-04-09 20:27:07,350:INFO:_master_model_container: 11
2023-04-09 20:27:07,350:INFO:_display_container: 2
2023-04-09 20:27:07,350:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-09 20:27:07,350:INFO:create_model() successfully completed......................................
2023-04-09 20:27:07,426:INFO:SubProcess create_model() end ==================================
2023-04-09 20:27:07,426:INFO:Creating metrics dataframe
2023-04-09 20:27:07,430:INFO:Initializing Extra Trees Classifier
2023-04-09 20:27:07,430:INFO:Total runtime is 0.49202935298283895 minutes
2023-04-09 20:27:07,430:INFO:SubProcess create_model() called ==================================
2023-04-09 20:27:07,431:INFO:Initializing create_model()
2023-04-09 20:27:07,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:27:07,431:INFO:Checking exceptions
2023-04-09 20:27:07,431:INFO:Importing libraries
2023-04-09 20:27:07,431:INFO:Copying training dataset
2023-04-09 20:27:07,435:INFO:Defining folds
2023-04-09 20:27:07,435:INFO:Declaring metric variables
2023-04-09 20:27:07,435:INFO:Importing untrained model
2023-04-09 20:27:07,436:INFO:Extra Trees Classifier Imported successfully
2023-04-09 20:27:07,436:INFO:Starting cross validation
2023-04-09 20:27:07,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:27:10,135:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:27:10,149:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:27:10,160:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:27:12,463:INFO:Calculating mean and std
2023-04-09 20:27:12,464:INFO:Creating metrics dataframe
2023-04-09 20:27:12,631:INFO:Uploading results into container
2023-04-09 20:27:12,631:INFO:Uploading model into container now
2023-04-09 20:27:12,632:INFO:_master_model_container: 12
2023-04-09 20:27:12,632:INFO:_display_container: 2
2023-04-09 20:27:12,632:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4017, verbose=0, warm_start=False)
2023-04-09 20:27:12,632:INFO:create_model() successfully completed......................................
2023-04-09 20:27:12,708:INFO:SubProcess create_model() end ==================================
2023-04-09 20:27:12,708:INFO:Creating metrics dataframe
2023-04-09 20:27:12,712:INFO:Initializing Extreme Gradient Boosting
2023-04-09 20:27:12,712:INFO:Total runtime is 0.5800665100415547 minutes
2023-04-09 20:27:12,712:INFO:SubProcess create_model() called ==================================
2023-04-09 20:27:12,712:INFO:Initializing create_model()
2023-04-09 20:27:12,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:27:12,712:INFO:Checking exceptions
2023-04-09 20:27:12,712:INFO:Importing libraries
2023-04-09 20:27:12,712:INFO:Copying training dataset
2023-04-09 20:27:12,717:INFO:Defining folds
2023-04-09 20:27:12,717:INFO:Declaring metric variables
2023-04-09 20:27:12,718:INFO:Importing untrained model
2023-04-09 20:27:12,718:INFO:Extreme Gradient Boosting Imported successfully
2023-04-09 20:27:12,718:INFO:Starting cross validation
2023-04-09 20:27:12,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:27:17,662:INFO:Calculating mean and std
2023-04-09 20:27:17,662:INFO:Creating metrics dataframe
2023-04-09 20:27:17,783:INFO:Uploading results into container
2023-04-09 20:27:17,784:INFO:Uploading model into container now
2023-04-09 20:27:17,784:INFO:_master_model_container: 13
2023-04-09 20:27:17,785:INFO:_display_container: 2
2023-04-09 20:27:17,785:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-09 20:27:17,785:INFO:create_model() successfully completed......................................
2023-04-09 20:27:17,855:INFO:SubProcess create_model() end ==================================
2023-04-09 20:27:17,855:INFO:Creating metrics dataframe
2023-04-09 20:27:17,859:INFO:Initializing Light Gradient Boosting Machine
2023-04-09 20:27:17,859:INFO:Total runtime is 0.6658498128255208 minutes
2023-04-09 20:27:17,859:INFO:SubProcess create_model() called ==================================
2023-04-09 20:27:17,859:INFO:Initializing create_model()
2023-04-09 20:27:17,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:27:17,860:INFO:Checking exceptions
2023-04-09 20:27:17,860:INFO:Importing libraries
2023-04-09 20:27:17,860:INFO:Copying training dataset
2023-04-09 20:27:17,868:INFO:Defining folds
2023-04-09 20:27:17,868:INFO:Declaring metric variables
2023-04-09 20:27:17,869:INFO:Importing untrained model
2023-04-09 20:27:17,869:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:27:17,869:INFO:Starting cross validation
2023-04-09 20:27:17,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:27:19,933:INFO:Calculating mean and std
2023-04-09 20:27:19,933:INFO:Creating metrics dataframe
2023-04-09 20:27:20,063:INFO:Uploading results into container
2023-04-09 20:27:20,063:INFO:Uploading model into container now
2023-04-09 20:27:20,064:INFO:_master_model_container: 14
2023-04-09 20:27:20,064:INFO:_display_container: 2
2023-04-09 20:27:20,064:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4017, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:27:20,065:INFO:create_model() successfully completed......................................
2023-04-09 20:27:20,136:INFO:SubProcess create_model() end ==================================
2023-04-09 20:27:20,136:INFO:Creating metrics dataframe
2023-04-09 20:27:20,140:INFO:Initializing Dummy Classifier
2023-04-09 20:27:20,140:INFO:Total runtime is 0.7038760423660279 minutes
2023-04-09 20:27:20,140:INFO:SubProcess create_model() called ==================================
2023-04-09 20:27:20,140:INFO:Initializing create_model()
2023-04-09 20:27:20,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A0CF00760>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:27:20,140:INFO:Checking exceptions
2023-04-09 20:27:20,140:INFO:Importing libraries
2023-04-09 20:27:20,140:INFO:Copying training dataset
2023-04-09 20:27:20,146:INFO:Defining folds
2023-04-09 20:27:20,146:INFO:Declaring metric variables
2023-04-09 20:27:20,146:INFO:Importing untrained model
2023-04-09 20:27:20,146:INFO:Dummy Classifier Imported successfully
2023-04-09 20:27:20,147:INFO:Starting cross validation
2023-04-09 20:27:20,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:27:21,453:INFO:Calculating mean and std
2023-04-09 20:27:21,454:INFO:Creating metrics dataframe
2023-04-09 20:27:21,578:INFO:Uploading results into container
2023-04-09 20:27:21,579:INFO:Uploading model into container now
2023-04-09 20:27:21,579:INFO:_master_model_container: 15
2023-04-09 20:27:21,579:INFO:_display_container: 2
2023-04-09 20:27:21,580:INFO:DummyClassifier(constant=None, random_state=4017, strategy='prior')
2023-04-09 20:27:21,580:INFO:create_model() successfully completed......................................
2023-04-09 20:27:21,652:INFO:SubProcess create_model() end ==================================
2023-04-09 20:27:21,652:INFO:Creating metrics dataframe
2023-04-09 20:27:21,659:INFO:Initializing create_model()
2023-04-09 20:27:21,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4017, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:27:21,660:INFO:Checking exceptions
2023-04-09 20:27:21,660:INFO:Importing libraries
2023-04-09 20:27:21,660:INFO:Copying training dataset
2023-04-09 20:27:21,665:INFO:Defining folds
2023-04-09 20:27:21,665:INFO:Declaring metric variables
2023-04-09 20:27:21,665:INFO:Importing untrained model
2023-04-09 20:27:21,665:INFO:Declaring custom model
2023-04-09 20:27:21,665:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:27:21,667:INFO:Cross validation set to False
2023-04-09 20:27:21,667:INFO:Fitting Model
2023-04-09 20:27:22,037:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4017, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:27:22,037:INFO:create_model() successfully completed......................................
2023-04-09 20:27:22,132:INFO:_master_model_container: 15
2023-04-09 20:27:22,132:INFO:_display_container: 2
2023-04-09 20:27:22,132:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4017, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:27:22,132:INFO:compare_models() successfully completed......................................
2023-04-09 20:27:22,133:INFO:Initializing finalize_model()
2023-04-09 20:27:22,133:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4017, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-09 20:27:22,133:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4017, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:27:22,137:INFO:Initializing create_model()
2023-04-09 20:27:22,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4017, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-09 20:27:22,137:INFO:Checking exceptions
2023-04-09 20:27:22,138:INFO:Importing libraries
2023-04-09 20:27:22,138:INFO:Copying training dataset
2023-04-09 20:27:22,138:INFO:Defining folds
2023-04-09 20:27:22,138:INFO:Declaring metric variables
2023-04-09 20:27:22,138:INFO:Importing untrained model
2023-04-09 20:27:22,138:INFO:Declaring custom model
2023-04-09 20:27:22,139:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:27:22,140:INFO:Cross validation set to False
2023-04-09 20:27:22,140:INFO:Fitting Model
2023-04-09 20:27:22,453:INFO:Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'months_employed',
                                             'years_employed',
                                             'current_address_year',
                                             'personal_account_m',
                                             'personal_account_y', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=4017, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-04-09 20:27:22,453:INFO:create_model() successfully completed......................................
2023-04-09 20:27:22,559:INFO:_master_model_container: 15
2023-04-09 20:27:22,559:INFO:_display_container: 2
2023-04-09 20:27:22,564:INFO:Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'months_employed',
                                             'years_employed',
                                             'current_address_year',
                                             'personal_account_m',
                                             'personal_account_y', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=4017, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-04-09 20:27:22,564:INFO:finalize_model() successfully completed......................................
2023-04-09 20:27:22,743:INFO:Initializing predict_model()
2023-04-09 20:27:22,743:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A06BA1970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'months_employed',
                                             'years_employed',
                                             'current_address_year',
                                             'personal_account_m',
                                             'personal_account_y', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=4017, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000022A11474B80>)
2023-04-09 20:27:22,743:INFO:Checking exceptions
2023-04-09 20:27:22,743:INFO:Preloading libraries
2023-04-09 20:27:22,743:INFO:Set up data.
2023-04-09 20:27:22,753:INFO:Set up index.
2023-04-09 20:45:59,434:INFO:PyCaret ClassificationExperiment
2023-04-09 20:45:59,434:INFO:Logging name: clf-default-name
2023-04-09 20:45:59,434:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-09 20:45:59,434:INFO:version 3.0.0
2023-04-09 20:45:59,434:INFO:Initializing setup()
2023-04-09 20:45:59,434:INFO:self.USI: 811f
2023-04-09 20:45:59,434:INFO:self._variable_keys: {'memory', 'USI', 'html_param', 'X', '_available_plots', 'exp_id', 'y_train', 'fold_generator', 'fix_imbalance', 'gpu_n_jobs_param', 'fold_shuffle_param', 'log_plots_param', 'pipeline', 'target_param', 'seed', 'n_jobs_param', 'is_multiclass', 'exp_name_log', 'idx', 'y_test', '_ml_usecase', 'gpu_param', 'X_train', 'X_test', 'data', 'fold_groups_param', 'y', 'logging_param'}
2023-04-09 20:45:59,434:INFO:Checking environment
2023-04-09 20:45:59,434:INFO:python_version: 3.9.15
2023-04-09 20:45:59,434:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-04-09 20:45:59,434:INFO:machine: AMD64
2023-04-09 20:45:59,434:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-09 20:45:59,434:INFO:Memory: svmem(total=34189594624, available=20277043200, percent=40.7, used=13912551424, free=20277043200)
2023-04-09 20:45:59,434:INFO:Physical Core: 6
2023-04-09 20:45:59,434:INFO:Logical Core: 12
2023-04-09 20:45:59,435:INFO:Checking libraries
2023-04-09 20:45:59,435:INFO:System:
2023-04-09 20:45:59,435:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-04-09 20:45:59,435:INFO:executable: C:\Users\anilc\anaconda3\python.exe
2023-04-09 20:45:59,435:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-09 20:45:59,435:INFO:PyCaret required dependencies:
2023-04-09 20:45:59,435:INFO:                 pip: 22.3.1
2023-04-09 20:45:59,435:INFO:          setuptools: 60.10.0
2023-04-09 20:45:59,435:INFO:             pycaret: 3.0.0
2023-04-09 20:45:59,435:INFO:             IPython: 8.7.0
2023-04-09 20:45:59,435:INFO:          ipywidgets: 7.6.5
2023-04-09 20:45:59,435:INFO:                tqdm: 4.64.1
2023-04-09 20:45:59,435:INFO:               numpy: 1.21.5
2023-04-09 20:45:59,435:INFO:              pandas: 1.4.4
2023-04-09 20:45:59,435:INFO:              jinja2: 3.1.2
2023-04-09 20:45:59,435:INFO:               scipy: 1.9.3
2023-04-09 20:45:59,435:INFO:              joblib: 1.2.0
2023-04-09 20:45:59,435:INFO:             sklearn: 1.0.2
2023-04-09 20:45:59,435:INFO:                pyod: 1.0.9
2023-04-09 20:45:59,435:INFO:            imblearn: 0.10.1
2023-04-09 20:45:59,435:INFO:   category_encoders: 2.6.0
2023-04-09 20:45:59,435:INFO:            lightgbm: 3.3.5
2023-04-09 20:45:59,435:INFO:               numba: 0.56.4
2023-04-09 20:45:59,435:INFO:            requests: 2.28.1
2023-04-09 20:45:59,435:INFO:          matplotlib: 3.6.2
2023-04-09 20:45:59,435:INFO:          scikitplot: 0.3.7
2023-04-09 20:45:59,435:INFO:         yellowbrick: 1.5
2023-04-09 20:45:59,436:INFO:              plotly: 5.9.0
2023-04-09 20:45:59,436:INFO:             kaleido: 0.2.1
2023-04-09 20:45:59,436:INFO:         statsmodels: 0.13.2
2023-04-09 20:45:59,436:INFO:              sktime: 0.16.1
2023-04-09 20:45:59,436:INFO:               tbats: 1.1.2
2023-04-09 20:45:59,436:INFO:            pmdarima: 2.0.3
2023-04-09 20:45:59,436:INFO:              psutil: 5.9.0
2023-04-09 20:45:59,436:INFO:PyCaret optional dependencies:
2023-04-09 20:45:59,436:INFO:                shap: Not installed
2023-04-09 20:45:59,436:INFO:           interpret: Not installed
2023-04-09 20:45:59,436:INFO:                umap: Not installed
2023-04-09 20:45:59,436:INFO:    pandas_profiling: 4.1.2
2023-04-09 20:45:59,436:INFO:  explainerdashboard: Not installed
2023-04-09 20:45:59,436:INFO:             autoviz: 0.1.58
2023-04-09 20:45:59,436:INFO:           fairlearn: Not installed
2023-04-09 20:45:59,436:INFO:             xgboost: 1.7.5
2023-04-09 20:45:59,436:INFO:            catboost: Not installed
2023-04-09 20:45:59,436:INFO:              kmodes: Not installed
2023-04-09 20:45:59,436:INFO:             mlxtend: 0.21.0
2023-04-09 20:45:59,436:INFO:       statsforecast: Not installed
2023-04-09 20:45:59,436:INFO:        tune_sklearn: Not installed
2023-04-09 20:45:59,436:INFO:                 ray: Not installed
2023-04-09 20:45:59,436:INFO:            hyperopt: Not installed
2023-04-09 20:45:59,436:INFO:              optuna: Not installed
2023-04-09 20:45:59,436:INFO:               skopt: Not installed
2023-04-09 20:45:59,436:INFO:              mlflow: Not installed
2023-04-09 20:45:59,437:INFO:              gradio: Not installed
2023-04-09 20:45:59,437:INFO:             fastapi: Not installed
2023-04-09 20:45:59,437:INFO:             uvicorn: Not installed
2023-04-09 20:45:59,437:INFO:              m2cgen: Not installed
2023-04-09 20:45:59,437:INFO:           evidently: Not installed
2023-04-09 20:45:59,437:INFO:               fugue: Not installed
2023-04-09 20:45:59,437:INFO:           streamlit: Not installed
2023-04-09 20:45:59,437:INFO:             prophet: Not installed
2023-04-09 20:45:59,437:INFO:None
2023-04-09 20:45:59,437:INFO:Set up data.
2023-04-09 20:45:59,449:INFO:Set up train/test split.
2023-04-09 20:45:59,458:INFO:Set up index.
2023-04-09 20:45:59,458:INFO:Set up folding strategy.
2023-04-09 20:45:59,458:INFO:Assigning column types.
2023-04-09 20:45:59,461:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-09 20:45:59,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-09 20:45:59,501:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:45:59,524:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:45:59,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:45:59,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-09 20:45:59,564:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:45:59,588:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:45:59,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:45:59,591:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-09 20:45:59,630:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:45:59,655:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:45:59,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:45:59,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:45:59,720:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:45:59,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:45:59,722:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-09 20:45:59,784:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:45:59,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:45:59,847:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:45:59,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:45:59,852:INFO:Preparing preprocessing pipeline...
2023-04-09 20:45:59,853:INFO:Set up simple imputation.
2023-04-09 20:45:59,854:INFO:Set up column name cleaning.
2023-04-09 20:45:59,879:INFO:Finished creating preprocessing pipeline.
2023-04-09 20:45:59,884:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'years_employed',
                                             'current_address_year', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_score_3',
                                             'risk_score_4', 'risk_score_5',
                                             'ext_quality_score',
                                             '...
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-09 20:45:59,884:INFO:Creating final display dataframe.
2023-04-09 20:45:59,972:INFO:Setup _display_container:                     Description             Value
0                    Session id               276
1                        Target          e_signed
2                   Target type            Binary
3           Original data shape       (17908, 21)
4        Transformed data shape       (17908, 21)
5   Transformed train set shape       (12535, 21)
6    Transformed test set shape        (5373, 21)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              811f
2023-04-09 20:46:00,040:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:46:00,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:46:00,105:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:46:00,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:46:00,107:INFO:setup() successfully completed in 0.77s...............
2023-04-09 20:46:00,197:INFO:Initializing compare_models()
2023-04-09 20:46:00,197:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-09 20:46:00,197:INFO:Checking exceptions
2023-04-09 20:46:00,201:INFO:Preparing display monitor
2023-04-09 20:46:00,203:INFO:Initializing Logistic Regression
2023-04-09 20:46:00,203:INFO:Total runtime is 0.0 minutes
2023-04-09 20:46:00,203:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:00,203:INFO:Initializing create_model()
2023-04-09 20:46:00,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:00,203:INFO:Checking exceptions
2023-04-09 20:46:00,203:INFO:Importing libraries
2023-04-09 20:46:00,203:INFO:Copying training dataset
2023-04-09 20:46:00,209:INFO:Defining folds
2023-04-09 20:46:00,209:INFO:Declaring metric variables
2023-04-09 20:46:00,210:INFO:Importing untrained model
2023-04-09 20:46:00,210:INFO:Logistic Regression Imported successfully
2023-04-09 20:46:00,210:INFO:Starting cross validation
2023-04-09 20:46:00,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:06,171:INFO:Calculating mean and std
2023-04-09 20:46:06,172:INFO:Creating metrics dataframe
2023-04-09 20:46:06,302:INFO:Uploading results into container
2023-04-09 20:46:06,302:INFO:Uploading model into container now
2023-04-09 20:46:06,303:INFO:_master_model_container: 1
2023-04-09 20:46:06,303:INFO:_display_container: 2
2023-04-09 20:46:06,303:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=276, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-09 20:46:06,303:INFO:create_model() successfully completed......................................
2023-04-09 20:46:06,382:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:06,382:INFO:Creating metrics dataframe
2023-04-09 20:46:06,387:INFO:Initializing K Neighbors Classifier
2023-04-09 20:46:06,387:INFO:Total runtime is 0.1030552347501119 minutes
2023-04-09 20:46:06,387:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:06,387:INFO:Initializing create_model()
2023-04-09 20:46:06,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:06,387:INFO:Checking exceptions
2023-04-09 20:46:06,387:INFO:Importing libraries
2023-04-09 20:46:06,387:INFO:Copying training dataset
2023-04-09 20:46:06,393:INFO:Defining folds
2023-04-09 20:46:06,393:INFO:Declaring metric variables
2023-04-09 20:46:06,393:INFO:Importing untrained model
2023-04-09 20:46:06,393:INFO:K Neighbors Classifier Imported successfully
2023-04-09 20:46:06,393:INFO:Starting cross validation
2023-04-09 20:46:06,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:07,408:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:07,434:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:07,517:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:07,550:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:07,567:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:07,571:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:07,694:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:07,727:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:09,858:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:09,884:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:46:10,346:INFO:Calculating mean and std
2023-04-09 20:46:10,346:INFO:Creating metrics dataframe
2023-04-09 20:46:10,483:INFO:Uploading results into container
2023-04-09 20:46:10,483:INFO:Uploading model into container now
2023-04-09 20:46:10,483:INFO:_master_model_container: 2
2023-04-09 20:46:10,483:INFO:_display_container: 2
2023-04-09 20:46:10,484:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-09 20:46:10,484:INFO:create_model() successfully completed......................................
2023-04-09 20:46:10,553:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:10,553:INFO:Creating metrics dataframe
2023-04-09 20:46:10,557:INFO:Initializing Naive Bayes
2023-04-09 20:46:10,557:INFO:Total runtime is 0.17255886793136596 minutes
2023-04-09 20:46:10,557:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:10,557:INFO:Initializing create_model()
2023-04-09 20:46:10,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:10,557:INFO:Checking exceptions
2023-04-09 20:46:10,557:INFO:Importing libraries
2023-04-09 20:46:10,557:INFO:Copying training dataset
2023-04-09 20:46:10,563:INFO:Defining folds
2023-04-09 20:46:10,563:INFO:Declaring metric variables
2023-04-09 20:46:10,563:INFO:Importing untrained model
2023-04-09 20:46:10,564:INFO:Naive Bayes Imported successfully
2023-04-09 20:46:10,564:INFO:Starting cross validation
2023-04-09 20:46:10,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:11,697:INFO:Calculating mean and std
2023-04-09 20:46:11,697:INFO:Creating metrics dataframe
2023-04-09 20:46:11,825:INFO:Uploading results into container
2023-04-09 20:46:11,826:INFO:Uploading model into container now
2023-04-09 20:46:11,826:INFO:_master_model_container: 3
2023-04-09 20:46:11,826:INFO:_display_container: 2
2023-04-09 20:46:11,826:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-09 20:46:11,826:INFO:create_model() successfully completed......................................
2023-04-09 20:46:11,898:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:11,898:INFO:Creating metrics dataframe
2023-04-09 20:46:11,903:INFO:Initializing Decision Tree Classifier
2023-04-09 20:46:11,903:INFO:Total runtime is 0.19498722950617473 minutes
2023-04-09 20:46:11,903:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:11,904:INFO:Initializing create_model()
2023-04-09 20:46:11,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:11,904:INFO:Checking exceptions
2023-04-09 20:46:11,904:INFO:Importing libraries
2023-04-09 20:46:11,904:INFO:Copying training dataset
2023-04-09 20:46:11,909:INFO:Defining folds
2023-04-09 20:46:11,909:INFO:Declaring metric variables
2023-04-09 20:46:11,909:INFO:Importing untrained model
2023-04-09 20:46:11,910:INFO:Decision Tree Classifier Imported successfully
2023-04-09 20:46:11,910:INFO:Starting cross validation
2023-04-09 20:46:11,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:13,444:INFO:Calculating mean and std
2023-04-09 20:46:13,445:INFO:Creating metrics dataframe
2023-04-09 20:46:13,582:INFO:Uploading results into container
2023-04-09 20:46:13,583:INFO:Uploading model into container now
2023-04-09 20:46:13,583:INFO:_master_model_container: 4
2023-04-09 20:46:13,583:INFO:_display_container: 2
2023-04-09 20:46:13,584:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=276, splitter='best')
2023-04-09 20:46:13,584:INFO:create_model() successfully completed......................................
2023-04-09 20:46:13,656:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:13,656:INFO:Creating metrics dataframe
2023-04-09 20:46:13,661:INFO:Initializing SVM - Linear Kernel
2023-04-09 20:46:13,661:INFO:Total runtime is 0.22428417603174847 minutes
2023-04-09 20:46:13,661:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:13,661:INFO:Initializing create_model()
2023-04-09 20:46:13,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:13,661:INFO:Checking exceptions
2023-04-09 20:46:13,661:INFO:Importing libraries
2023-04-09 20:46:13,661:INFO:Copying training dataset
2023-04-09 20:46:13,669:INFO:Defining folds
2023-04-09 20:46:13,669:INFO:Declaring metric variables
2023-04-09 20:46:13,669:INFO:Importing untrained model
2023-04-09 20:46:13,670:INFO:SVM - Linear Kernel Imported successfully
2023-04-09 20:46:13,670:INFO:Starting cross validation
2023-04-09 20:46:13,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:14,185:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,186:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,250:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,280:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,309:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,349:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,356:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,363:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:46:14,382:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,389:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:46:14,395:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:14,400:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:46:14,412:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:46:15,287:INFO:Calculating mean and std
2023-04-09 20:46:15,287:INFO:Creating metrics dataframe
2023-04-09 20:46:15,430:INFO:Uploading results into container
2023-04-09 20:46:15,431:INFO:Uploading model into container now
2023-04-09 20:46:15,431:INFO:_master_model_container: 5
2023-04-09 20:46:15,431:INFO:_display_container: 2
2023-04-09 20:46:15,432:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=276, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-09 20:46:15,432:INFO:create_model() successfully completed......................................
2023-04-09 20:46:15,503:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:15,503:INFO:Creating metrics dataframe
2023-04-09 20:46:15,506:INFO:Initializing Ridge Classifier
2023-04-09 20:46:15,507:INFO:Total runtime is 0.25506033102671305 minutes
2023-04-09 20:46:15,507:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:15,507:INFO:Initializing create_model()
2023-04-09 20:46:15,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:15,507:INFO:Checking exceptions
2023-04-09 20:46:15,507:INFO:Importing libraries
2023-04-09 20:46:15,507:INFO:Copying training dataset
2023-04-09 20:46:15,513:INFO:Defining folds
2023-04-09 20:46:15,513:INFO:Declaring metric variables
2023-04-09 20:46:15,513:INFO:Importing untrained model
2023-04-09 20:46:15,514:INFO:Ridge Classifier Imported successfully
2023-04-09 20:46:15,514:INFO:Starting cross validation
2023-04-09 20:46:15,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:15,636:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,639:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,651:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,655:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,662:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,665:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,683:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,689:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,708:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:15,711:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:46:16,687:INFO:Calculating mean and std
2023-04-09 20:46:16,688:INFO:Creating metrics dataframe
2023-04-09 20:46:16,822:INFO:Uploading results into container
2023-04-09 20:46:16,823:INFO:Uploading model into container now
2023-04-09 20:46:16,823:INFO:_master_model_container: 6
2023-04-09 20:46:16,823:INFO:_display_container: 2
2023-04-09 20:46:16,823:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=276, solver='auto', tol=0.001)
2023-04-09 20:46:16,823:INFO:create_model() successfully completed......................................
2023-04-09 20:46:16,893:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:16,893:INFO:Creating metrics dataframe
2023-04-09 20:46:16,897:INFO:Initializing Random Forest Classifier
2023-04-09 20:46:16,897:INFO:Total runtime is 0.2782174428304036 minutes
2023-04-09 20:46:16,897:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:16,898:INFO:Initializing create_model()
2023-04-09 20:46:16,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:16,898:INFO:Checking exceptions
2023-04-09 20:46:16,898:INFO:Importing libraries
2023-04-09 20:46:16,898:INFO:Copying training dataset
2023-04-09 20:46:16,903:INFO:Defining folds
2023-04-09 20:46:16,903:INFO:Declaring metric variables
2023-04-09 20:46:16,903:INFO:Importing untrained model
2023-04-09 20:46:16,903:INFO:Random Forest Classifier Imported successfully
2023-04-09 20:46:16,903:INFO:Starting cross validation
2023-04-09 20:46:16,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:20,175:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:46:20,250:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:46:22,838:INFO:Calculating mean and std
2023-04-09 20:46:22,839:INFO:Creating metrics dataframe
2023-04-09 20:46:22,980:INFO:Uploading results into container
2023-04-09 20:46:22,981:INFO:Uploading model into container now
2023-04-09 20:46:22,981:INFO:_master_model_container: 7
2023-04-09 20:46:22,981:INFO:_display_container: 2
2023-04-09 20:46:22,981:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=276, verbose=0, warm_start=False)
2023-04-09 20:46:22,981:INFO:create_model() successfully completed......................................
2023-04-09 20:46:23,051:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:23,052:INFO:Creating metrics dataframe
2023-04-09 20:46:23,056:INFO:Initializing Quadratic Discriminant Analysis
2023-04-09 20:46:23,056:INFO:Total runtime is 0.3808750748634338 minutes
2023-04-09 20:46:23,056:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:23,056:INFO:Initializing create_model()
2023-04-09 20:46:23,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:23,056:INFO:Checking exceptions
2023-04-09 20:46:23,056:INFO:Importing libraries
2023-04-09 20:46:23,056:INFO:Copying training dataset
2023-04-09 20:46:23,062:INFO:Defining folds
2023-04-09 20:46:23,062:INFO:Declaring metric variables
2023-04-09 20:46:23,062:INFO:Importing untrained model
2023-04-09 20:46:23,062:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-09 20:46:23,062:INFO:Starting cross validation
2023-04-09 20:46:23,063:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:24,291:INFO:Calculating mean and std
2023-04-09 20:46:24,291:INFO:Creating metrics dataframe
2023-04-09 20:46:24,432:INFO:Uploading results into container
2023-04-09 20:46:24,433:INFO:Uploading model into container now
2023-04-09 20:46:24,433:INFO:_master_model_container: 8
2023-04-09 20:46:24,433:INFO:_display_container: 2
2023-04-09 20:46:24,433:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-09 20:46:24,433:INFO:create_model() successfully completed......................................
2023-04-09 20:46:24,504:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:24,504:INFO:Creating metrics dataframe
2023-04-09 20:46:24,508:INFO:Initializing Ada Boost Classifier
2023-04-09 20:46:24,508:INFO:Total runtime is 0.40508259137471514 minutes
2023-04-09 20:46:24,509:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:24,509:INFO:Initializing create_model()
2023-04-09 20:46:24,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:24,509:INFO:Checking exceptions
2023-04-09 20:46:24,509:INFO:Importing libraries
2023-04-09 20:46:24,509:INFO:Copying training dataset
2023-04-09 20:46:24,515:INFO:Defining folds
2023-04-09 20:46:24,515:INFO:Declaring metric variables
2023-04-09 20:46:24,515:INFO:Importing untrained model
2023-04-09 20:46:24,515:INFO:Ada Boost Classifier Imported successfully
2023-04-09 20:46:24,515:INFO:Starting cross validation
2023-04-09 20:46:24,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:27,435:INFO:Calculating mean and std
2023-04-09 20:46:27,435:INFO:Creating metrics dataframe
2023-04-09 20:46:27,590:INFO:Uploading results into container
2023-04-09 20:46:27,590:INFO:Uploading model into container now
2023-04-09 20:46:27,591:INFO:_master_model_container: 9
2023-04-09 20:46:27,591:INFO:_display_container: 2
2023-04-09 20:46:27,591:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=276)
2023-04-09 20:46:27,591:INFO:create_model() successfully completed......................................
2023-04-09 20:46:27,661:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:27,661:INFO:Creating metrics dataframe
2023-04-09 20:46:27,665:INFO:Initializing Gradient Boosting Classifier
2023-04-09 20:46:27,665:INFO:Total runtime is 0.457696791489919 minutes
2023-04-09 20:46:27,665:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:27,665:INFO:Initializing create_model()
2023-04-09 20:46:27,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:27,666:INFO:Checking exceptions
2023-04-09 20:46:27,666:INFO:Importing libraries
2023-04-09 20:46:27,666:INFO:Copying training dataset
2023-04-09 20:46:27,672:INFO:Defining folds
2023-04-09 20:46:27,672:INFO:Declaring metric variables
2023-04-09 20:46:27,672:INFO:Importing untrained model
2023-04-09 20:46:27,672:INFO:Gradient Boosting Classifier Imported successfully
2023-04-09 20:46:27,672:INFO:Starting cross validation
2023-04-09 20:46:27,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:35,808:INFO:Calculating mean and std
2023-04-09 20:46:35,809:INFO:Creating metrics dataframe
2023-04-09 20:46:36,064:INFO:Uploading results into container
2023-04-09 20:46:36,065:INFO:Uploading model into container now
2023-04-09 20:46:36,065:INFO:_master_model_container: 10
2023-04-09 20:46:36,065:INFO:_display_container: 2
2023-04-09 20:46:36,066:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=276, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-09 20:46:36,066:INFO:create_model() successfully completed......................................
2023-04-09 20:46:36,155:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:36,155:INFO:Creating metrics dataframe
2023-04-09 20:46:36,160:INFO:Initializing Linear Discriminant Analysis
2023-04-09 20:46:36,160:INFO:Total runtime is 0.5992803732554117 minutes
2023-04-09 20:46:36,161:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:36,161:INFO:Initializing create_model()
2023-04-09 20:46:36,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:36,161:INFO:Checking exceptions
2023-04-09 20:46:36,161:INFO:Importing libraries
2023-04-09 20:46:36,161:INFO:Copying training dataset
2023-04-09 20:46:36,168:INFO:Defining folds
2023-04-09 20:46:36,168:INFO:Declaring metric variables
2023-04-09 20:46:36,168:INFO:Importing untrained model
2023-04-09 20:46:36,169:INFO:Linear Discriminant Analysis Imported successfully
2023-04-09 20:46:36,169:INFO:Starting cross validation
2023-04-09 20:46:36,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:38,050:INFO:Calculating mean and std
2023-04-09 20:46:38,051:INFO:Creating metrics dataframe
2023-04-09 20:46:38,256:INFO:Uploading results into container
2023-04-09 20:46:38,256:INFO:Uploading model into container now
2023-04-09 20:46:38,257:INFO:_master_model_container: 11
2023-04-09 20:46:38,257:INFO:_display_container: 2
2023-04-09 20:46:38,257:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-09 20:46:38,257:INFO:create_model() successfully completed......................................
2023-04-09 20:46:38,344:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:38,344:INFO:Creating metrics dataframe
2023-04-09 20:46:38,349:INFO:Initializing Extra Trees Classifier
2023-04-09 20:46:38,349:INFO:Total runtime is 0.6357590556144713 minutes
2023-04-09 20:46:38,349:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:38,349:INFO:Initializing create_model()
2023-04-09 20:46:38,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:38,350:INFO:Checking exceptions
2023-04-09 20:46:38,350:INFO:Importing libraries
2023-04-09 20:46:38,350:INFO:Copying training dataset
2023-04-09 20:46:38,355:INFO:Defining folds
2023-04-09 20:46:38,355:INFO:Declaring metric variables
2023-04-09 20:46:38,356:INFO:Importing untrained model
2023-04-09 20:46:38,356:INFO:Extra Trees Classifier Imported successfully
2023-04-09 20:46:38,356:INFO:Starting cross validation
2023-04-09 20:46:38,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:41,011:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:46:42,931:INFO:Calculating mean and std
2023-04-09 20:46:42,931:INFO:Creating metrics dataframe
2023-04-09 20:46:43,104:INFO:Uploading results into container
2023-04-09 20:46:43,105:INFO:Uploading model into container now
2023-04-09 20:46:43,105:INFO:_master_model_container: 12
2023-04-09 20:46:43,105:INFO:_display_container: 2
2023-04-09 20:46:43,106:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=276, verbose=0, warm_start=False)
2023-04-09 20:46:43,106:INFO:create_model() successfully completed......................................
2023-04-09 20:46:43,194:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:43,194:INFO:Creating metrics dataframe
2023-04-09 20:46:43,203:INFO:Initializing Extreme Gradient Boosting
2023-04-09 20:46:43,203:INFO:Total runtime is 0.7166655500729877 minutes
2023-04-09 20:46:43,203:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:43,204:INFO:Initializing create_model()
2023-04-09 20:46:43,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:43,204:INFO:Checking exceptions
2023-04-09 20:46:43,204:INFO:Importing libraries
2023-04-09 20:46:43,204:INFO:Copying training dataset
2023-04-09 20:46:43,215:INFO:Defining folds
2023-04-09 20:46:43,215:INFO:Declaring metric variables
2023-04-09 20:46:43,215:INFO:Importing untrained model
2023-04-09 20:46:43,216:INFO:Extreme Gradient Boosting Imported successfully
2023-04-09 20:46:43,216:INFO:Starting cross validation
2023-04-09 20:46:43,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:49,644:INFO:Calculating mean and std
2023-04-09 20:46:49,644:INFO:Creating metrics dataframe
2023-04-09 20:46:49,811:INFO:Uploading results into container
2023-04-09 20:46:49,812:INFO:Uploading model into container now
2023-04-09 20:46:49,812:INFO:_master_model_container: 13
2023-04-09 20:46:49,812:INFO:_display_container: 2
2023-04-09 20:46:49,813:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-09 20:46:49,813:INFO:create_model() successfully completed......................................
2023-04-09 20:46:49,887:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:49,887:INFO:Creating metrics dataframe
2023-04-09 20:46:49,891:INFO:Initializing Light Gradient Boosting Machine
2023-04-09 20:46:49,891:INFO:Total runtime is 0.8281303604443866 minutes
2023-04-09 20:46:49,892:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:49,892:INFO:Initializing create_model()
2023-04-09 20:46:49,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:49,892:INFO:Checking exceptions
2023-04-09 20:46:49,892:INFO:Importing libraries
2023-04-09 20:46:49,892:INFO:Copying training dataset
2023-04-09 20:46:49,899:INFO:Defining folds
2023-04-09 20:46:49,899:INFO:Declaring metric variables
2023-04-09 20:46:49,899:INFO:Importing untrained model
2023-04-09 20:46:49,900:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:46:49,900:INFO:Starting cross validation
2023-04-09 20:46:49,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:53,236:INFO:Calculating mean and std
2023-04-09 20:46:53,237:INFO:Creating metrics dataframe
2023-04-09 20:46:53,424:INFO:Uploading results into container
2023-04-09 20:46:53,425:INFO:Uploading model into container now
2023-04-09 20:46:53,425:INFO:_master_model_container: 14
2023-04-09 20:46:53,425:INFO:_display_container: 2
2023-04-09 20:46:53,426:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:46:53,426:INFO:create_model() successfully completed......................................
2023-04-09 20:46:53,505:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:53,505:INFO:Creating metrics dataframe
2023-04-09 20:46:53,510:INFO:Initializing Dummy Classifier
2023-04-09 20:46:53,510:INFO:Total runtime is 0.8884417295455931 minutes
2023-04-09 20:46:53,510:INFO:SubProcess create_model() called ==================================
2023-04-09 20:46:53,510:INFO:Initializing create_model()
2023-04-09 20:46:53,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A06FD5E20>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:53,510:INFO:Checking exceptions
2023-04-09 20:46:53,510:INFO:Importing libraries
2023-04-09 20:46:53,510:INFO:Copying training dataset
2023-04-09 20:46:53,517:INFO:Defining folds
2023-04-09 20:46:53,517:INFO:Declaring metric variables
2023-04-09 20:46:53,517:INFO:Importing untrained model
2023-04-09 20:46:53,517:INFO:Dummy Classifier Imported successfully
2023-04-09 20:46:53,518:INFO:Starting cross validation
2023-04-09 20:46:53,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:46:55,102:INFO:Calculating mean and std
2023-04-09 20:46:55,102:INFO:Creating metrics dataframe
2023-04-09 20:46:55,285:INFO:Uploading results into container
2023-04-09 20:46:55,286:INFO:Uploading model into container now
2023-04-09 20:46:55,286:INFO:_master_model_container: 15
2023-04-09 20:46:55,287:INFO:_display_container: 2
2023-04-09 20:46:55,287:INFO:DummyClassifier(constant=None, random_state=276, strategy='prior')
2023-04-09 20:46:55,287:INFO:create_model() successfully completed......................................
2023-04-09 20:46:55,364:INFO:SubProcess create_model() end ==================================
2023-04-09 20:46:55,364:INFO:Creating metrics dataframe
2023-04-09 20:46:55,369:INFO:Initializing create_model()
2023-04-09 20:46:55,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:46:55,369:INFO:Checking exceptions
2023-04-09 20:46:55,370:INFO:Importing libraries
2023-04-09 20:46:55,370:INFO:Copying training dataset
2023-04-09 20:46:55,376:INFO:Defining folds
2023-04-09 20:46:55,376:INFO:Declaring metric variables
2023-04-09 20:46:55,376:INFO:Importing untrained model
2023-04-09 20:46:55,376:INFO:Declaring custom model
2023-04-09 20:46:55,377:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:46:55,378:INFO:Cross validation set to False
2023-04-09 20:46:55,378:INFO:Fitting Model
2023-04-09 20:46:55,726:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:46:55,726:INFO:create_model() successfully completed......................................
2023-04-09 20:46:55,817:INFO:_master_model_container: 15
2023-04-09 20:46:55,817:INFO:_display_container: 2
2023-04-09 20:46:55,818:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:46:55,818:INFO:compare_models() successfully completed......................................
2023-04-09 20:46:55,818:INFO:Initializing finalize_model()
2023-04-09 20:46:55,818:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-09 20:46:55,819:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:46:55,822:INFO:Initializing create_model()
2023-04-09 20:46:55,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-09 20:46:55,822:INFO:Checking exceptions
2023-04-09 20:46:55,823:INFO:Importing libraries
2023-04-09 20:46:55,823:INFO:Copying training dataset
2023-04-09 20:46:55,823:INFO:Defining folds
2023-04-09 20:46:55,823:INFO:Declaring metric variables
2023-04-09 20:46:55,824:INFO:Importing untrained model
2023-04-09 20:46:55,824:INFO:Declaring custom model
2023-04-09 20:46:55,824:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:46:55,825:INFO:Cross validation set to False
2023-04-09 20:46:55,825:INFO:Fitting Model
2023-04-09 20:46:56,047:INFO:Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'years_employed',
                                             'current_address_year', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_score_3',
                                             'risk_score_4', 'risk_score_5',
                                             'ext_quality_score',
                                             '...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=276,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-04-09 20:46:56,047:INFO:create_model() successfully completed......................................
2023-04-09 20:46:56,154:INFO:_master_model_container: 15
2023-04-09 20:46:56,154:INFO:_display_container: 2
2023-04-09 20:46:56,160:INFO:Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'years_employed',
                                             'current_address_year', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_score_3',
                                             'risk_score_4', 'risk_score_5',
                                             'ext_quality_score',
                                             '...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=276,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-04-09 20:46:56,160:INFO:finalize_model() successfully completed......................................
2023-04-09 20:46:56,369:INFO:Initializing predict_model()
2023-04-09 20:46:56,369:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A10EDEBB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'years_employed',
                                             'current_address_year', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_score_3',
                                             'risk_score_4', 'risk_score_5',
                                             'ext_quality_score',
                                             '...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=276,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000022A10E99DC0>)
2023-04-09 20:46:56,369:INFO:Checking exceptions
2023-04-09 20:46:56,369:INFO:Preloading libraries
2023-04-09 20:46:56,369:INFO:Set up data.
2023-04-09 20:46:56,380:INFO:Set up index.
2023-04-09 20:48:51,965:INFO:PyCaret ClassificationExperiment
2023-04-09 20:48:51,965:INFO:Logging name: clf-default-name
2023-04-09 20:48:51,965:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-09 20:48:51,965:INFO:version 3.0.0
2023-04-09 20:48:51,965:INFO:Initializing setup()
2023-04-09 20:48:51,965:INFO:self.USI: 8939
2023-04-09 20:48:51,965:INFO:self._variable_keys: {'memory', 'USI', 'html_param', 'X', '_available_plots', 'exp_id', 'y_train', 'fold_generator', 'fix_imbalance', 'gpu_n_jobs_param', 'fold_shuffle_param', 'log_plots_param', 'pipeline', 'target_param', 'seed', 'n_jobs_param', 'is_multiclass', 'exp_name_log', 'idx', 'y_test', '_ml_usecase', 'gpu_param', 'X_train', 'X_test', 'data', 'fold_groups_param', 'y', 'logging_param'}
2023-04-09 20:48:51,965:INFO:Checking environment
2023-04-09 20:48:51,965:INFO:python_version: 3.9.15
2023-04-09 20:48:51,965:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-04-09 20:48:51,965:INFO:machine: AMD64
2023-04-09 20:48:51,965:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-09 20:48:51,965:INFO:Memory: svmem(total=34189594624, available=18574221312, percent=45.7, used=15615373312, free=18574221312)
2023-04-09 20:48:51,966:INFO:Physical Core: 6
2023-04-09 20:48:51,966:INFO:Logical Core: 12
2023-04-09 20:48:51,966:INFO:Checking libraries
2023-04-09 20:48:51,966:INFO:System:
2023-04-09 20:48:51,966:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-04-09 20:48:51,966:INFO:executable: C:\Users\anilc\anaconda3\python.exe
2023-04-09 20:48:51,966:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-09 20:48:51,966:INFO:PyCaret required dependencies:
2023-04-09 20:48:51,966:INFO:                 pip: 22.3.1
2023-04-09 20:48:51,966:INFO:          setuptools: 60.10.0
2023-04-09 20:48:51,966:INFO:             pycaret: 3.0.0
2023-04-09 20:48:51,966:INFO:             IPython: 8.7.0
2023-04-09 20:48:51,966:INFO:          ipywidgets: 7.6.5
2023-04-09 20:48:51,966:INFO:                tqdm: 4.64.1
2023-04-09 20:48:51,966:INFO:               numpy: 1.21.5
2023-04-09 20:48:51,966:INFO:              pandas: 1.4.4
2023-04-09 20:48:51,966:INFO:              jinja2: 3.1.2
2023-04-09 20:48:51,966:INFO:               scipy: 1.9.3
2023-04-09 20:48:51,966:INFO:              joblib: 1.2.0
2023-04-09 20:48:51,966:INFO:             sklearn: 1.0.2
2023-04-09 20:48:51,966:INFO:                pyod: 1.0.9
2023-04-09 20:48:51,967:INFO:            imblearn: 0.10.1
2023-04-09 20:48:51,967:INFO:   category_encoders: 2.6.0
2023-04-09 20:48:51,967:INFO:            lightgbm: 3.3.5
2023-04-09 20:48:51,967:INFO:               numba: 0.56.4
2023-04-09 20:48:51,967:INFO:            requests: 2.28.1
2023-04-09 20:48:51,967:INFO:          matplotlib: 3.6.2
2023-04-09 20:48:51,967:INFO:          scikitplot: 0.3.7
2023-04-09 20:48:51,967:INFO:         yellowbrick: 1.5
2023-04-09 20:48:51,967:INFO:              plotly: 5.9.0
2023-04-09 20:48:51,967:INFO:             kaleido: 0.2.1
2023-04-09 20:48:51,967:INFO:         statsmodels: 0.13.2
2023-04-09 20:48:51,967:INFO:              sktime: 0.16.1
2023-04-09 20:48:51,967:INFO:               tbats: 1.1.2
2023-04-09 20:48:51,967:INFO:            pmdarima: 2.0.3
2023-04-09 20:48:51,967:INFO:              psutil: 5.9.0
2023-04-09 20:48:51,967:INFO:PyCaret optional dependencies:
2023-04-09 20:48:51,967:INFO:                shap: Not installed
2023-04-09 20:48:51,967:INFO:           interpret: Not installed
2023-04-09 20:48:51,967:INFO:                umap: Not installed
2023-04-09 20:48:51,967:INFO:    pandas_profiling: 4.1.2
2023-04-09 20:48:51,967:INFO:  explainerdashboard: Not installed
2023-04-09 20:48:51,967:INFO:             autoviz: 0.1.58
2023-04-09 20:48:51,967:INFO:           fairlearn: Not installed
2023-04-09 20:48:51,967:INFO:             xgboost: 1.7.5
2023-04-09 20:48:51,967:INFO:            catboost: Not installed
2023-04-09 20:48:51,967:INFO:              kmodes: Not installed
2023-04-09 20:48:51,967:INFO:             mlxtend: 0.21.0
2023-04-09 20:48:51,967:INFO:       statsforecast: Not installed
2023-04-09 20:48:51,967:INFO:        tune_sklearn: Not installed
2023-04-09 20:48:51,968:INFO:                 ray: Not installed
2023-04-09 20:48:51,968:INFO:            hyperopt: Not installed
2023-04-09 20:48:51,968:INFO:              optuna: Not installed
2023-04-09 20:48:51,968:INFO:               skopt: Not installed
2023-04-09 20:48:51,968:INFO:              mlflow: Not installed
2023-04-09 20:48:51,968:INFO:              gradio: Not installed
2023-04-09 20:48:51,968:INFO:             fastapi: Not installed
2023-04-09 20:48:51,968:INFO:             uvicorn: Not installed
2023-04-09 20:48:51,968:INFO:              m2cgen: Not installed
2023-04-09 20:48:51,968:INFO:           evidently: Not installed
2023-04-09 20:48:51,968:INFO:               fugue: Not installed
2023-04-09 20:48:51,968:INFO:           streamlit: Not installed
2023-04-09 20:48:51,968:INFO:             prophet: Not installed
2023-04-09 20:48:51,968:INFO:None
2023-04-09 20:48:51,968:INFO:Set up data.
2023-04-09 20:48:51,978:INFO:Set up train/test split.
2023-04-09 20:48:51,988:INFO:Set up index.
2023-04-09 20:48:51,988:INFO:Set up folding strategy.
2023-04-09 20:48:51,988:INFO:Assigning column types.
2023-04-09 20:48:51,992:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-09 20:48:52,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-09 20:48:52,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:48:52,057:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:48:52,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:48:52,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-09 20:48:52,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:48:52,126:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:48:52,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:48:52,129:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-09 20:48:52,173:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:48:52,200:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:48:52,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:48:52,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-09 20:48:52,272:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:48:52,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:48:52,275:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-09 20:48:52,339:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:48:52,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:48:52,407:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:48:52,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:48:52,411:INFO:Preparing preprocessing pipeline...
2023-04-09 20:48:52,412:INFO:Set up simple imputation.
2023-04-09 20:48:52,413:INFO:Set up column name cleaning.
2023-04-09 20:48:52,438:INFO:Finished creating preprocessing pipeline.
2023-04-09 20:48:52,444:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'years_employed',
                                             'current_address_year', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_score_3',
                                             'risk_score_4', 'risk_score_5',
                                             'ext_quality_score',
                                             '...
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-09 20:48:52,444:INFO:Creating final display dataframe.
2023-04-09 20:48:52,553:INFO:Setup _display_container:                     Description             Value
0                    Session id              8145
1                        Target          e_signed
2                   Target type            Binary
3           Original data shape       (17908, 21)
4        Transformed data shape       (17908, 21)
5   Transformed train set shape       (12535, 21)
6    Transformed test set shape        (5373, 21)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              8939
2023-04-09 20:48:52,626:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:48:52,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:48:52,694:INFO:Soft dependency imported: xgboost: 1.7.5
2023-04-09 20:48:52,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-09 20:48:52,696:INFO:setup() successfully completed in 2.12s...............
2023-04-09 20:48:52,820:INFO:Initializing compare_models()
2023-04-09 20:48:52,820:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-09 20:48:52,821:INFO:Checking exceptions
2023-04-09 20:48:52,825:INFO:Preparing display monitor
2023-04-09 20:48:52,826:INFO:Initializing Logistic Regression
2023-04-09 20:48:52,826:INFO:Total runtime is 0.0 minutes
2023-04-09 20:48:52,826:INFO:SubProcess create_model() called ==================================
2023-04-09 20:48:52,827:INFO:Initializing create_model()
2023-04-09 20:48:52,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:48:52,827:INFO:Checking exceptions
2023-04-09 20:48:52,827:INFO:Importing libraries
2023-04-09 20:48:52,827:INFO:Copying training dataset
2023-04-09 20:48:52,833:INFO:Defining folds
2023-04-09 20:48:52,833:INFO:Declaring metric variables
2023-04-09 20:48:52,833:INFO:Importing untrained model
2023-04-09 20:48:52,834:INFO:Logistic Regression Imported successfully
2023-04-09 20:48:52,834:INFO:Starting cross validation
2023-04-09 20:48:52,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:48:54,493:INFO:Calculating mean and std
2023-04-09 20:48:54,494:INFO:Creating metrics dataframe
2023-04-09 20:48:54,678:INFO:Uploading results into container
2023-04-09 20:48:54,679:INFO:Uploading model into container now
2023-04-09 20:48:54,679:INFO:_master_model_container: 1
2023-04-09 20:48:54,679:INFO:_display_container: 2
2023-04-09 20:48:54,679:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8145, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-09 20:48:54,679:INFO:create_model() successfully completed......................................
2023-04-09 20:48:54,758:INFO:SubProcess create_model() end ==================================
2023-04-09 20:48:54,758:INFO:Creating metrics dataframe
2023-04-09 20:48:54,761:INFO:Initializing K Neighbors Classifier
2023-04-09 20:48:54,761:INFO:Total runtime is 0.03223550319671631 minutes
2023-04-09 20:48:54,761:INFO:SubProcess create_model() called ==================================
2023-04-09 20:48:54,762:INFO:Initializing create_model()
2023-04-09 20:48:54,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:48:54,762:INFO:Checking exceptions
2023-04-09 20:48:54,762:INFO:Importing libraries
2023-04-09 20:48:54,762:INFO:Copying training dataset
2023-04-09 20:48:54,767:INFO:Defining folds
2023-04-09 20:48:54,767:INFO:Declaring metric variables
2023-04-09 20:48:54,767:INFO:Importing untrained model
2023-04-09 20:48:54,768:INFO:K Neighbors Classifier Imported successfully
2023-04-09 20:48:54,768:INFO:Starting cross validation
2023-04-09 20:48:54,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:48:56,030:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,074:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,089:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,125:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,143:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,241:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,248:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,319:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,552:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:56,570:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-04-09 20:48:58,744:INFO:Calculating mean and std
2023-04-09 20:48:58,744:INFO:Creating metrics dataframe
2023-04-09 20:48:58,932:INFO:Uploading results into container
2023-04-09 20:48:58,932:INFO:Uploading model into container now
2023-04-09 20:48:58,933:INFO:_master_model_container: 2
2023-04-09 20:48:58,933:INFO:_display_container: 2
2023-04-09 20:48:58,933:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-09 20:48:58,934:INFO:create_model() successfully completed......................................
2023-04-09 20:48:59,008:INFO:SubProcess create_model() end ==================================
2023-04-09 20:48:59,008:INFO:Creating metrics dataframe
2023-04-09 20:48:59,011:INFO:Initializing Naive Bayes
2023-04-09 20:48:59,013:INFO:Total runtime is 0.10310785373051962 minutes
2023-04-09 20:48:59,013:INFO:SubProcess create_model() called ==================================
2023-04-09 20:48:59,013:INFO:Initializing create_model()
2023-04-09 20:48:59,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:48:59,013:INFO:Checking exceptions
2023-04-09 20:48:59,013:INFO:Importing libraries
2023-04-09 20:48:59,013:INFO:Copying training dataset
2023-04-09 20:48:59,018:INFO:Defining folds
2023-04-09 20:48:59,018:INFO:Declaring metric variables
2023-04-09 20:48:59,019:INFO:Importing untrained model
2023-04-09 20:48:59,019:INFO:Naive Bayes Imported successfully
2023-04-09 20:48:59,019:INFO:Starting cross validation
2023-04-09 20:48:59,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:00,518:INFO:Calculating mean and std
2023-04-09 20:49:00,519:INFO:Creating metrics dataframe
2023-04-09 20:49:00,696:INFO:Uploading results into container
2023-04-09 20:49:00,697:INFO:Uploading model into container now
2023-04-09 20:49:00,697:INFO:_master_model_container: 3
2023-04-09 20:49:00,697:INFO:_display_container: 2
2023-04-09 20:49:00,697:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-09 20:49:00,697:INFO:create_model() successfully completed......................................
2023-04-09 20:49:00,771:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:00,772:INFO:Creating metrics dataframe
2023-04-09 20:49:00,775:INFO:Initializing Decision Tree Classifier
2023-04-09 20:49:00,775:INFO:Total runtime is 0.13247958024342854 minutes
2023-04-09 20:49:00,776:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:00,776:INFO:Initializing create_model()
2023-04-09 20:49:00,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:00,776:INFO:Checking exceptions
2023-04-09 20:49:00,776:INFO:Importing libraries
2023-04-09 20:49:00,776:INFO:Copying training dataset
2023-04-09 20:49:00,781:INFO:Defining folds
2023-04-09 20:49:00,781:INFO:Declaring metric variables
2023-04-09 20:49:00,781:INFO:Importing untrained model
2023-04-09 20:49:00,783:INFO:Decision Tree Classifier Imported successfully
2023-04-09 20:49:00,783:INFO:Starting cross validation
2023-04-09 20:49:00,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:02,694:INFO:Calculating mean and std
2023-04-09 20:49:02,695:INFO:Creating metrics dataframe
2023-04-09 20:49:02,874:INFO:Uploading results into container
2023-04-09 20:49:02,874:INFO:Uploading model into container now
2023-04-09 20:49:02,875:INFO:_master_model_container: 4
2023-04-09 20:49:02,875:INFO:_display_container: 2
2023-04-09 20:49:02,875:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8145, splitter='best')
2023-04-09 20:49:02,875:INFO:create_model() successfully completed......................................
2023-04-09 20:49:02,951:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:02,951:INFO:Creating metrics dataframe
2023-04-09 20:49:02,955:INFO:Initializing SVM - Linear Kernel
2023-04-09 20:49:02,955:INFO:Total runtime is 0.16880812247594196 minutes
2023-04-09 20:49:02,955:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:02,956:INFO:Initializing create_model()
2023-04-09 20:49:02,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:02,956:INFO:Checking exceptions
2023-04-09 20:49:02,956:INFO:Importing libraries
2023-04-09 20:49:02,956:INFO:Copying training dataset
2023-04-09 20:49:02,963:INFO:Defining folds
2023-04-09 20:49:02,963:INFO:Declaring metric variables
2023-04-09 20:49:02,963:INFO:Importing untrained model
2023-04-09 20:49:02,964:INFO:SVM - Linear Kernel Imported successfully
2023-04-09 20:49:02,964:INFO:Starting cross validation
2023-04-09 20:49:02,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:03,373:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,544:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,627:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,633:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:49:03,649:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,650:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,655:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:49:03,664:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,670:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-09 20:49:03,703:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,714:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,718:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:03,738:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-09 20:49:04,881:INFO:Calculating mean and std
2023-04-09 20:49:04,882:INFO:Creating metrics dataframe
2023-04-09 20:49:05,067:INFO:Uploading results into container
2023-04-09 20:49:05,068:INFO:Uploading model into container now
2023-04-09 20:49:05,068:INFO:_master_model_container: 5
2023-04-09 20:49:05,068:INFO:_display_container: 2
2023-04-09 20:49:05,069:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8145, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-09 20:49:05,069:INFO:create_model() successfully completed......................................
2023-04-09 20:49:05,143:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:05,143:INFO:Creating metrics dataframe
2023-04-09 20:49:05,147:INFO:Initializing Ridge Classifier
2023-04-09 20:49:05,147:INFO:Total runtime is 0.2053451100985209 minutes
2023-04-09 20:49:05,148:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:05,148:INFO:Initializing create_model()
2023-04-09 20:49:05,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:05,148:INFO:Checking exceptions
2023-04-09 20:49:05,148:INFO:Importing libraries
2023-04-09 20:49:05,148:INFO:Copying training dataset
2023-04-09 20:49:05,153:INFO:Defining folds
2023-04-09 20:49:05,155:INFO:Declaring metric variables
2023-04-09 20:49:05,155:INFO:Importing untrained model
2023-04-09 20:49:05,156:INFO:Ridge Classifier Imported successfully
2023-04-09 20:49:05,156:INFO:Starting cross validation
2023-04-09 20:49:05,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:05,279:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,287:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,297:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,313:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,317:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,332:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,333:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,341:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,360:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:05,364:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\anilc\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-09 20:49:06,677:INFO:Calculating mean and std
2023-04-09 20:49:06,677:INFO:Creating metrics dataframe
2023-04-09 20:49:06,864:INFO:Uploading results into container
2023-04-09 20:49:06,865:INFO:Uploading model into container now
2023-04-09 20:49:06,865:INFO:_master_model_container: 6
2023-04-09 20:49:06,865:INFO:_display_container: 2
2023-04-09 20:49:06,865:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=8145, solver='auto', tol=0.001)
2023-04-09 20:49:06,865:INFO:create_model() successfully completed......................................
2023-04-09 20:49:06,940:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:06,940:INFO:Creating metrics dataframe
2023-04-09 20:49:06,944:INFO:Initializing Random Forest Classifier
2023-04-09 20:49:06,944:INFO:Total runtime is 0.23529610633850098 minutes
2023-04-09 20:49:06,944:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:06,945:INFO:Initializing create_model()
2023-04-09 20:49:06,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:06,945:INFO:Checking exceptions
2023-04-09 20:49:06,945:INFO:Importing libraries
2023-04-09 20:49:06,945:INFO:Copying training dataset
2023-04-09 20:49:06,951:INFO:Defining folds
2023-04-09 20:49:06,951:INFO:Declaring metric variables
2023-04-09 20:49:06,951:INFO:Importing untrained model
2023-04-09 20:49:06,951:INFO:Random Forest Classifier Imported successfully
2023-04-09 20:49:06,951:INFO:Starting cross validation
2023-04-09 20:49:06,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:10,690:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:49:10,810:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:49:11,165:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:49:13,601:INFO:Calculating mean and std
2023-04-09 20:49:13,602:INFO:Creating metrics dataframe
2023-04-09 20:49:13,793:INFO:Uploading results into container
2023-04-09 20:49:13,794:INFO:Uploading model into container now
2023-04-09 20:49:13,794:INFO:_master_model_container: 7
2023-04-09 20:49:13,794:INFO:_display_container: 2
2023-04-09 20:49:13,795:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8145, verbose=0, warm_start=False)
2023-04-09 20:49:13,795:INFO:create_model() successfully completed......................................
2023-04-09 20:49:13,869:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:13,869:INFO:Creating metrics dataframe
2023-04-09 20:49:13,873:INFO:Initializing Quadratic Discriminant Analysis
2023-04-09 20:49:13,873:INFO:Total runtime is 0.3507715026537577 minutes
2023-04-09 20:49:13,874:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:13,874:INFO:Initializing create_model()
2023-04-09 20:49:13,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:13,874:INFO:Checking exceptions
2023-04-09 20:49:13,874:INFO:Importing libraries
2023-04-09 20:49:13,874:INFO:Copying training dataset
2023-04-09 20:49:13,880:INFO:Defining folds
2023-04-09 20:49:13,880:INFO:Declaring metric variables
2023-04-09 20:49:13,880:INFO:Importing untrained model
2023-04-09 20:49:13,881:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-09 20:49:13,881:INFO:Starting cross validation
2023-04-09 20:49:13,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:15,833:INFO:Calculating mean and std
2023-04-09 20:49:15,833:INFO:Creating metrics dataframe
2023-04-09 20:49:16,046:INFO:Uploading results into container
2023-04-09 20:49:16,047:INFO:Uploading model into container now
2023-04-09 20:49:16,047:INFO:_master_model_container: 8
2023-04-09 20:49:16,047:INFO:_display_container: 2
2023-04-09 20:49:16,047:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-09 20:49:16,047:INFO:create_model() successfully completed......................................
2023-04-09 20:49:16,132:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:16,132:INFO:Creating metrics dataframe
2023-04-09 20:49:16,136:INFO:Initializing Ada Boost Classifier
2023-04-09 20:49:16,136:INFO:Total runtime is 0.388497789700826 minutes
2023-04-09 20:49:16,137:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:16,137:INFO:Initializing create_model()
2023-04-09 20:49:16,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:16,137:INFO:Checking exceptions
2023-04-09 20:49:16,137:INFO:Importing libraries
2023-04-09 20:49:16,137:INFO:Copying training dataset
2023-04-09 20:49:16,146:INFO:Defining folds
2023-04-09 20:49:16,146:INFO:Declaring metric variables
2023-04-09 20:49:16,147:INFO:Importing untrained model
2023-04-09 20:49:16,147:INFO:Ada Boost Classifier Imported successfully
2023-04-09 20:49:16,147:INFO:Starting cross validation
2023-04-09 20:49:16,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:20,564:INFO:Calculating mean and std
2023-04-09 20:49:20,564:INFO:Creating metrics dataframe
2023-04-09 20:49:20,793:INFO:Uploading results into container
2023-04-09 20:49:20,794:INFO:Uploading model into container now
2023-04-09 20:49:20,795:INFO:_master_model_container: 9
2023-04-09 20:49:20,795:INFO:_display_container: 2
2023-04-09 20:49:20,795:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8145)
2023-04-09 20:49:20,795:INFO:create_model() successfully completed......................................
2023-04-09 20:49:20,879:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:20,879:INFO:Creating metrics dataframe
2023-04-09 20:49:20,884:INFO:Initializing Gradient Boosting Classifier
2023-04-09 20:49:20,884:INFO:Total runtime is 0.4676182826360067 minutes
2023-04-09 20:49:20,884:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:20,884:INFO:Initializing create_model()
2023-04-09 20:49:20,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:20,884:INFO:Checking exceptions
2023-04-09 20:49:20,884:INFO:Importing libraries
2023-04-09 20:49:20,884:INFO:Copying training dataset
2023-04-09 20:49:20,891:INFO:Defining folds
2023-04-09 20:49:20,891:INFO:Declaring metric variables
2023-04-09 20:49:20,891:INFO:Importing untrained model
2023-04-09 20:49:20,891:INFO:Gradient Boosting Classifier Imported successfully
2023-04-09 20:49:20,892:INFO:Starting cross validation
2023-04-09 20:49:20,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:28,534:INFO:Calculating mean and std
2023-04-09 20:49:28,534:INFO:Creating metrics dataframe
2023-04-09 20:49:28,736:INFO:Uploading results into container
2023-04-09 20:49:28,736:INFO:Uploading model into container now
2023-04-09 20:49:28,736:INFO:_master_model_container: 10
2023-04-09 20:49:28,737:INFO:_display_container: 2
2023-04-09 20:49:28,737:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8145, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-09 20:49:28,737:INFO:create_model() successfully completed......................................
2023-04-09 20:49:28,810:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:28,811:INFO:Creating metrics dataframe
2023-04-09 20:49:28,814:INFO:Initializing Linear Discriminant Analysis
2023-04-09 20:49:28,816:INFO:Total runtime is 0.5998170773188274 minutes
2023-04-09 20:49:28,816:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:28,816:INFO:Initializing create_model()
2023-04-09 20:49:28,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:28,816:INFO:Checking exceptions
2023-04-09 20:49:28,816:INFO:Importing libraries
2023-04-09 20:49:28,816:INFO:Copying training dataset
2023-04-09 20:49:28,821:INFO:Defining folds
2023-04-09 20:49:28,821:INFO:Declaring metric variables
2023-04-09 20:49:28,821:INFO:Importing untrained model
2023-04-09 20:49:28,821:INFO:Linear Discriminant Analysis Imported successfully
2023-04-09 20:49:28,823:INFO:Starting cross validation
2023-04-09 20:49:28,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:30,512:INFO:Calculating mean and std
2023-04-09 20:49:30,513:INFO:Creating metrics dataframe
2023-04-09 20:49:30,711:INFO:Uploading results into container
2023-04-09 20:49:30,711:INFO:Uploading model into container now
2023-04-09 20:49:30,711:INFO:_master_model_container: 11
2023-04-09 20:49:30,711:INFO:_display_container: 2
2023-04-09 20:49:30,712:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-09 20:49:30,712:INFO:create_model() successfully completed......................................
2023-04-09 20:49:30,787:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:30,787:INFO:Creating metrics dataframe
2023-04-09 20:49:30,791:INFO:Initializing Extra Trees Classifier
2023-04-09 20:49:30,792:INFO:Total runtime is 0.6327509721120199 minutes
2023-04-09 20:49:30,792:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:30,792:INFO:Initializing create_model()
2023-04-09 20:49:30,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:30,792:INFO:Checking exceptions
2023-04-09 20:49:30,792:INFO:Importing libraries
2023-04-09 20:49:30,792:INFO:Copying training dataset
2023-04-09 20:49:30,797:INFO:Defining folds
2023-04-09 20:49:30,797:INFO:Declaring metric variables
2023-04-09 20:49:30,797:INFO:Importing untrained model
2023-04-09 20:49:30,798:INFO:Extra Trees Classifier Imported successfully
2023-04-09 20:49:30,798:INFO:Starting cross validation
2023-04-09 20:49:30,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:33,460:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:49:33,479:WARNING:C:\Users\anilc\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-09 20:49:35,809:INFO:Calculating mean and std
2023-04-09 20:49:35,810:INFO:Creating metrics dataframe
2023-04-09 20:49:36,023:INFO:Uploading results into container
2023-04-09 20:49:36,023:INFO:Uploading model into container now
2023-04-09 20:49:36,024:INFO:_master_model_container: 12
2023-04-09 20:49:36,024:INFO:_display_container: 2
2023-04-09 20:49:36,024:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8145, verbose=0, warm_start=False)
2023-04-09 20:49:36,024:INFO:create_model() successfully completed......................................
2023-04-09 20:49:36,101:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:36,101:INFO:Creating metrics dataframe
2023-04-09 20:49:36,107:INFO:Initializing Extreme Gradient Boosting
2023-04-09 20:49:36,107:INFO:Total runtime is 0.7213395595550538 minutes
2023-04-09 20:49:36,107:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:36,107:INFO:Initializing create_model()
2023-04-09 20:49:36,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:36,107:INFO:Checking exceptions
2023-04-09 20:49:36,107:INFO:Importing libraries
2023-04-09 20:49:36,107:INFO:Copying training dataset
2023-04-09 20:49:36,113:INFO:Defining folds
2023-04-09 20:49:36,113:INFO:Declaring metric variables
2023-04-09 20:49:36,113:INFO:Importing untrained model
2023-04-09 20:49:36,114:INFO:Extreme Gradient Boosting Imported successfully
2023-04-09 20:49:36,114:INFO:Starting cross validation
2023-04-09 20:49:36,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:42,780:INFO:Calculating mean and std
2023-04-09 20:49:42,780:INFO:Creating metrics dataframe
2023-04-09 20:49:42,994:INFO:Uploading results into container
2023-04-09 20:49:42,995:INFO:Uploading model into container now
2023-04-09 20:49:42,995:INFO:_master_model_container: 13
2023-04-09 20:49:42,995:INFO:_display_container: 2
2023-04-09 20:49:42,996:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-04-09 20:49:42,996:INFO:create_model() successfully completed......................................
2023-04-09 20:49:43,069:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:43,070:INFO:Creating metrics dataframe
2023-04-09 20:49:43,075:INFO:Initializing Light Gradient Boosting Machine
2023-04-09 20:49:43,075:INFO:Total runtime is 0.8374731699625652 minutes
2023-04-09 20:49:43,075:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:43,075:INFO:Initializing create_model()
2023-04-09 20:49:43,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:43,075:INFO:Checking exceptions
2023-04-09 20:49:43,075:INFO:Importing libraries
2023-04-09 20:49:43,075:INFO:Copying training dataset
2023-04-09 20:49:43,080:INFO:Defining folds
2023-04-09 20:49:43,081:INFO:Declaring metric variables
2023-04-09 20:49:43,081:INFO:Importing untrained model
2023-04-09 20:49:43,081:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:49:43,081:INFO:Starting cross validation
2023-04-09 20:49:43,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:45,718:INFO:Calculating mean and std
2023-04-09 20:49:45,718:INFO:Creating metrics dataframe
2023-04-09 20:49:45,933:INFO:Uploading results into container
2023-04-09 20:49:45,933:INFO:Uploading model into container now
2023-04-09 20:49:45,934:INFO:_master_model_container: 14
2023-04-09 20:49:45,934:INFO:_display_container: 2
2023-04-09 20:49:45,934:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8145, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:49:45,934:INFO:create_model() successfully completed......................................
2023-04-09 20:49:46,011:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:46,011:INFO:Creating metrics dataframe
2023-04-09 20:49:46,016:INFO:Initializing Dummy Classifier
2023-04-09 20:49:46,016:INFO:Total runtime is 0.8864914735158285 minutes
2023-04-09 20:49:46,016:INFO:SubProcess create_model() called ==================================
2023-04-09 20:49:46,016:INFO:Initializing create_model()
2023-04-09 20:49:46,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022A67DD5A90>, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:46,016:INFO:Checking exceptions
2023-04-09 20:49:46,016:INFO:Importing libraries
2023-04-09 20:49:46,016:INFO:Copying training dataset
2023-04-09 20:49:46,023:INFO:Defining folds
2023-04-09 20:49:46,023:INFO:Declaring metric variables
2023-04-09 20:49:46,023:INFO:Importing untrained model
2023-04-09 20:49:46,023:INFO:Dummy Classifier Imported successfully
2023-04-09 20:49:46,023:INFO:Starting cross validation
2023-04-09 20:49:46,024:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-09 20:49:47,826:INFO:Calculating mean and std
2023-04-09 20:49:47,826:INFO:Creating metrics dataframe
2023-04-09 20:49:48,069:INFO:Uploading results into container
2023-04-09 20:49:48,070:INFO:Uploading model into container now
2023-04-09 20:49:48,070:INFO:_master_model_container: 15
2023-04-09 20:49:48,070:INFO:_display_container: 2
2023-04-09 20:49:48,071:INFO:DummyClassifier(constant=None, random_state=8145, strategy='prior')
2023-04-09 20:49:48,071:INFO:create_model() successfully completed......................................
2023-04-09 20:49:48,149:INFO:SubProcess create_model() end ==================================
2023-04-09 20:49:48,149:INFO:Creating metrics dataframe
2023-04-09 20:49:48,155:INFO:Initializing create_model()
2023-04-09 20:49:48,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8145, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-09 20:49:48,155:INFO:Checking exceptions
2023-04-09 20:49:48,156:INFO:Importing libraries
2023-04-09 20:49:48,157:INFO:Copying training dataset
2023-04-09 20:49:48,162:INFO:Defining folds
2023-04-09 20:49:48,162:INFO:Declaring metric variables
2023-04-09 20:49:48,162:INFO:Importing untrained model
2023-04-09 20:49:48,163:INFO:Declaring custom model
2023-04-09 20:49:48,163:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:49:48,163:INFO:Cross validation set to False
2023-04-09 20:49:48,163:INFO:Fitting Model
2023-04-09 20:49:48,526:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8145, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:49:48,526:INFO:create_model() successfully completed......................................
2023-04-09 20:49:48,611:INFO:_master_model_container: 15
2023-04-09 20:49:48,611:INFO:_display_container: 2
2023-04-09 20:49:48,612:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8145, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:49:48,612:INFO:compare_models() successfully completed......................................
2023-04-09 20:49:48,612:INFO:Initializing finalize_model()
2023-04-09 20:49:48,613:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8145, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-09 20:49:48,613:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8145, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-09 20:49:48,617:INFO:Initializing create_model()
2023-04-09 20:49:48,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8145, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-09 20:49:48,617:INFO:Checking exceptions
2023-04-09 20:49:48,617:INFO:Importing libraries
2023-04-09 20:49:48,617:INFO:Copying training dataset
2023-04-09 20:49:48,617:INFO:Defining folds
2023-04-09 20:49:48,618:INFO:Declaring metric variables
2023-04-09 20:49:48,618:INFO:Importing untrained model
2023-04-09 20:49:48,618:INFO:Declaring custom model
2023-04-09 20:49:48,618:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-09 20:49:48,619:INFO:Cross validation set to False
2023-04-09 20:49:48,619:INFO:Fitting Model
2023-04-09 20:49:48,910:INFO:Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'years_employed',
                                             'current_address_year', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_score_3',
                                             'risk_score_4', 'risk_score_5',
                                             'ext_quality_score',
                                             '...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=8145, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-04-09 20:49:48,910:INFO:create_model() successfully completed......................................
2023-04-09 20:49:49,014:INFO:_master_model_container: 15
2023-04-09 20:49:49,014:INFO:_display_container: 2
2023-04-09 20:49:49,019:INFO:Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'years_employed',
                                             'current_address_year', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_score_3',
                                             'risk_score_4', 'risk_score_5',
                                             'ext_quality_score',
                                             '...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=8145, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-04-09 20:49:49,019:INFO:finalize_model() successfully completed......................................
2023-04-09 20:49:49,253:INFO:Initializing predict_model()
2023-04-09 20:49:49,253:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022A113353D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\anilc\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['entry_id', 'age', 'home_owner',
                                             'income', 'years_employed',
                                             'current_address_year', 'has_debt',
                                             'amount_requested', 'risk_score',
                                             'risk_score_2', 'risk_score_3',
                                             'risk_score_4', 'risk_score_5',
                                             'ext_quality_score',
                                             '...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=8145, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000022A0F94A8B0>)
2023-04-09 20:49:49,253:INFO:Checking exceptions
2023-04-09 20:49:49,253:INFO:Preloading libraries
2023-04-09 20:49:49,253:INFO:Set up data.
2023-04-09 20:49:49,265:INFO:Set up index.
